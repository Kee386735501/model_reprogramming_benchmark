# model reprogramming benchmark  实验报告



**注解** ： 

1. **linear-probe finetune** :  在原有模型的基础上 ，加上这个分类头来应用于目标任务 ， 我们的微调也只微调这个分类头 
2. **fully-fintune** ：更改模型所有层（替换分类头），侧重于更改模型所有参数
3. **fine-tune classification head** ：只修改最后一层并对其微调
4. **model reprogramming**：模型重编程



### 实验设计

该实验主要是从三个维度来探究 model reporgramming 和 finetune 方法的性能上的差异，探究 model reprogramming 在什么时候有作用 ，优势区间在哪 

1. 探究不同 数据集 size 下对模型微调，模型重编程的影响 

2. 探究数据集差异（distance）对model reprogramming的影响 

3. 探究噪声（noise） 对 model reprogramming 的影响 

   



### Resnet18 实验结果

**实验1 ： 影响因素是数据集的大小**

**Cifar 10** 

*epoch 50 下训练，理论实际结果最佳可能有2%左右的浮动*

|                                   | 20%  | 40%  | 60%   | 80%  | 100% |
| --------------------------------- | ---- | ---- | ----- | ---- | ---- |
| **fully-fintune**                 | 92.7 | 94.0 | 94.7  | 95.1 | 95.6 |
| **fine-tune classification head** | 76.9 | 79.3 | 79.65 | 80.3 | 81.2 |
| **model reprogramming**           | 62.8 | 68.2 | 68.3  | 68.4 | 72.8 |
| **linear-probe finetune**         | 78.4 | 79.6 | 80.1  | 80.8 | 81.0 |

**Cifar100**

|                                   | 20%  | 40%  | 60%  | 80%  | 100%  |
| --------------------------------- | ---- | ---- | ---- | ---- | ----- |
| **fully-fintune**                 | 73.1 | 77.6 | 80.3 | 79.4 | 80.6  |
| **fine-tune classification head** | 50.2 | 55.2 | 57.8 | 58.8 | 59.74 |
| **model reprogramming**           | 32.1 | 34.7 | 35.7 | 36.6 | 39.4  |
| **linear-probe finetune**         | 52.8 | 56.8 | 58.0 | 59.1 | 60.0  |



**SVHN**

|                                   | 20%  | 40%  | 60%  | 80%   | 100% |
| --------------------------------- | ---- | ---- | ---- | ----- | ---- |
| **fully-fintune**                 |      |      |      |       |      |
| **fine-tune classification head** |      |      |      |       |      |
| **model reprogramming**           | 73.7 | 77.8 | 76.2 | 79.81 | 84.4 |
| **linear-probe finetune**         |      |      |      |       |      |



- **CIFAR-10 上：**
  - Fully-finetune 一开始就有很高性能，受数据量影响较小。
  - Model reprogramming 对数据量**非常敏感**，提升最大。
  - Fine-tune head 和 linear-probe 表现稳定，但增益一般。
- **CIFAR-100 上：**
  - 所有方法对数据量都更敏感，提升都在 **7–9%** 区间。
  - “fine-tune classification head” 和 “model reprogramming” 提升幅度更大，说明它们对更大的训练数据更依赖。

Cifar 10

| 策略                  | 20% 准确率 | 100% 准确率 | 绝对提升 (%) | 相对提升 (%) |
| --------------------- | ---------- | ----------- | ------------ | ------------ |
| Fully-finetune        | 92.7       | 95.6        | **2.9**      | **3.13%**    |
| Fine-tune head        | 76.9       | 81.2        | **4.3**      | **5.59%**    |
| Model reprogramming   | 62.8       | 72.8        | **10.0**     | **15.92%**   |
| Linear-probe finetune | 78.4       | 81.0        | **2.6**      | **3.32%**    |

Cifar100

| 策略                  | 20% 准确率 | 100% 准确率 | 绝对提升 (%) | 相对提升 (%) |
| --------------------- | ---------- | ----------- | ------------ | ------------ |
| Fully-finetune        | 73.1       | 80.6        | **7.5**      | **10.26%**   |
| Fine-tune head        | 50.2       | 59.74       | **9.54**     | **19.00%**   |
| Model reprogramming   | 32.1       | 39.4        | **7.3**      | **22.74%**   |
| Linear-probe finetune | 52.8       | 60.0        | **7.2**      | **13.64%**   |





**实验 2 ： 数据集的 distance 之间的差异** 

**实验方法**

Resnet18 是一个在 ImageNet1000 上训练的预训练模型 ，我们尝试使用和  ImageNet1000 差别较大的数据集进行实验对比 ，例如 domainnet 

我们这里实验使用的是 “quickdraw” ，“real” ， “infograph“ ， ”Clipart” ， “Sketch”
这五个数据集 。**单源数据集去训练 resnet18 ， 然后用另一个单源数据集去微调或者mr。**基于磁盘空间的限制 ，我这里 上游选择了 30 类 去训练 resnet18 模型 ， 然后下游选取 10类去做 fft 和 mr 

![image-20250417023030934](G:/model%20reprogramming/model_reprogramming_benchmark/assets/image-20250417023030934.png)



Real 是真实物品的图片，其他的类别多少都保留了对象结构特征，按照数据集的差异我们可以计算出数据集之间的distance



**FID（Fréchet Inception Distance）**

对于距离计算，我这里使用的是 FID（Fréchet Inception Distance），这是一种衡量两个图像集合在特征空间中分布差异的指标，通常用于：

- 比较生成图像与真实图像的相似度（比如 GAN 评估）
- 比较不同风格（domain）图像之间的分布差距
- 衡量图像迁移/风格转换/重编程等任务中的 **domain gap**

因此它是很适合我们的实验任务的，FID 并不是直接对比图像像素，而是先使用一个预训练网络（通常是 Inception-v3）提取图像特征向量，然后对这些特征向量的分布做统计建模，再计算两个分布的“距离”。

计算方法：

1. 给两个图像集合 $X$ 和 $Y$，用预训练的 Inception-v3 模型提取每张图像的特征（比如 2048 维的向量）。
2. 对两个集合的特征分别估计它们的 **多维高斯分布参数**：
   - 平均向量 $\mu_x, \mu_y$
   - 协方差矩阵 $\Sigma_x, \Sigma_y$
3. 然后用 **Fréchet 距离（Wasserstein-2 距离）** 计算两个分布的距离：

$$
\text{FID}(X, Y) = \| \mu_x - \mu_y \|^2 + \text{Tr} \left( \Sigma_x + \Sigma_y - 2(\Sigma_x \Sigma_y)^{1/2} \right)
$$

这里遇到一个问题，就是 Source Domain 和 Target Domain 的不同图片种类，比如Real的 cup 和 infograph 的 cup ，他们的 FID是否差别很大？，这里我是直接做均值计算来衡量两个类的 distance 
$$
\text{FID}(S, T) = \text{FID'}(S, T)/N_{ClassNumber}
$$
例如 Real 和 Infograph 的 FID 均值是 197.53

​	quickdraw 和 real 的 FID 均值是 336.36 ， 因此 quickdraw 明显是 比 infograph 离 Real 远的 

|      | **quickdraw** | Infograph | sketch | clipart | painting |
| ---- | ------------- | --------- | ------ | ------- | -------- |
| real | 336.36        | 197.53    | 203.97 | 197.53  | 160.04   |



**Maximum Mean Discrepancy（最大均值差异）**

MMD 的核心思想是：

> **如果两个分布在某个特征空间中的所有函数上的期望值都相等，那么这两个分布就是相同的。**

MMD 就是通过计算两个样本在某个 **再生核希尔伯特空间（RKHS）** 中的**均值嵌入（mean embedding）之间的距离**，来判断它们是否来自同一个分布。

设有两个分布 $P$ 和 $Q$，从它们中采样出两个样本集合：

- $X = \{x_1, \dots, x_m\} \sim P$
- $Y = \{y_1, \dots, y_n\} \sim Q$

在一个带核函数 $k$ 的 RKHS $\mathcal{H}$ 中，MMD 的无偏估计可以表示为：
$$
\text{MMD}^2(X, Y) = \frac{1}{m(m-1)} \sum_{i \neq j} k(x_i, x_j) + \frac{1}{n(n-1)} \sum_{i \neq j} k(y_i, y_j) - \frac{2}{mn} \sum_{i, j} k(x_i, y_j)
$$
其中 $k(x, y)$ 常用的是 **Gaussian 核函数** 或 **多项式核函数**：
$$
k(x, y) = \exp\left(-\frac{\|x - y\|^2}{2\sigma^2}\right)
$$


|      | **quickdraw** | Infograph | sketch | clipart | painting |
| ---- | ------------- | --------- | ------ | ------- | -------- |
| real | 0.0042        | 0.0139    | 0.0112 | 0.0134  |          |





**model reprogramming**

**上游(Quickdraw)**

![image-20250409163959468](G:/model%20reprogramming/model_reprogramming_benchmark/assets/image-20250409163959468.png)



**下游(Real)**

<img src="G:/model%20reprogramming/model_reprogramming_benchmark/assets/image-20250409163221044.png" alt="image-20250409163221044" style="zoom: 80%;" />



**fully fintune**

![image-20250409181212178](G:/model%20reprogramming/model_reprogramming_benchmark/assets/image-20250409181212178.png)



上游基于Sketch的训练结果是 86 % ，下游mr 的结果是 65% ，下游 ft的结果是 80% 左右。



后续数据以表格形式整理 

| upstream  | downstream | Train | MR   | FFT  |
| --------- | ---------- | ----- | ---- | ---- |
| quickdraw | Real       | 80.2  | 53.7 | 66.0 |
| Sketch    | Real       | 33.2  | 59.7 | 72.9 |
| Quckdraw  | Real       | 86.0  | 64.9 | 80.1 |
| Clipart   | Real       | 52.8  | 68.7 | 79.7 |
| Infograph | Real       | 23.2  | 56.5 | 72.9 |
| Real      | Sketch     | 75.8  | 41.2 | 50.6 |
| Real      | quickdraw  | 75.8  | 77.0 | 87.9 |
| Real      | clipart    | 75.8  | 47.8 | 62.1 |
| Real      | infograph  | 75.8  | 31.1 | 42.5 |

**实验分析**

一、**向 Real 的迁移（下游为 Real）**

- 向 Real 迁移时，**clipart** 的 MR 最高（68.7），重编程效果最好。

- **quickdraw** FID 虽大，但其迁移效果好，说明 Real 能够从其学到鲁棒特征。

- MR 和 FFT 在这组中 **一致偏高**，表明从其他子域迁移到 Real 相对容易。

二，**向 domainnet 域的迁移**

- **在 Real → X 的迁移中，MR 与 FID 呈“非单调弱相关”**：高 FID 不一定带来低 MR。

  **quickdraw 是最容易通过模型重编程迁移的目标域**，尽管其分布差异最大，表明：

  - 模型重编程不依赖视觉近似
  - 更依赖图像语义结构是否“可映射”

  **infograph 是最难迁移的目标域**，说明它在语义空间中与 real 差异较大。



