# model reprogramming benchmark  实验报告



**注解** ： 

1. **linear-probe finetune** :  在原有模型的基础上 ，加上这个分类头来应用于目标任务 ， 我们的微调也只微调这个分类头 
2. **fully-fintune** ：更改模型所有层（替换分类头），侧重于更改模型所有参数
3. **fine-tune classification head** ：只修改最后一层并对其微调
4. **model reprogramming**：模型重编程



### 实验设计

该实验主要是从三个维度来探究 model reporgramming 和 finetune 方法的性能上的差异，探究 model reprogramming 在什么时候有作用 ，优势区间在哪 

1. 探究不同 数据集 size 下对模型微调，模型重编程的影响 

2. 探究数据集差异（distance）对model reprogramming的影响 

3. 探究噪声（noise） 对 model reprogramming 的影响 

   

1. size 的影响 使用数据集 （Cifar 10 ，Cifar 100 ，svhn）







### Resnet18 实验结果

**实验1 ： 影响因素是数据集的大小**

**Cifar 10** 

*epoch 50 下训练，理论实际结果最佳可能有2%左右的浮动*

|                                   | 20%  | 40%  | 60%   | 80%  | 100% |
| --------------------------------- | ---- | ---- | ----- | ---- | ---- |
| **fully-fintune**                 | 92.7 | 94.0 | 94.7  | 95.1 | 95.6 |
| **fine-tune classification head** | 76.9 | 79.3 | 79.65 | 80.3 | 81.2 |
| **model reprogramming**           | 62.8 | 68.2 | 68.3  | 68.4 | 72.8 |
| **linear-probe finetune**         | 78.4 | 79.6 | 80.1  | 80.8 | 81.0 |

**Cifar100**

|                                   | 20%  | 40%  | 60%  | 80%  | 100%  |
| --------------------------------- | ---- | ---- | ---- | ---- | ----- |
| **fully-fintune**                 | 73.1 | 77.6 | 80.3 | 79.4 | 80.6  |
| **fine-tune classification head** | 50.2 | 55.2 | 57.8 | 58.8 | 59.74 |
| **model reprogramming**           | 32.1 | 34.7 | 35.7 | 36.6 | 39.4  |
| **linear-probe finetune**         | 52.8 | 56.8 | 58.0 | 59.1 | 60.0  |



**SVHN**

|                                   | 20%  | 40%  | 60%  | 80%   | 100% |
| --------------------------------- | ---- | ---- | ---- | ----- | ---- |
| **fully-fintune**                 |      |      |      |       |      |
| **fine-tune classification head** |      |      |      |       |      |
| **model reprogramming**           | 73.7 | 77.8 | 76.2 | 79.81 | 84.4 |
| **linear-probe finetune**         |      |      |      |       |      |



- **CIFAR-10 上：**
  - “model reprogramming” 对数据量最敏感，增长了 **10%**。
  - “fully-finetune” 和 “linear-probe finetune” 的提升都在 **3% 左右**，说明它们更稳定。
- **CIFAR-100 上：**
  - 所有方法对数据量都更敏感，提升都在 **7–9%** 区间。
  - “fine-tune classification head” 和 “model reprogramming” 提升幅度更大，说明它们对更大的训练数据更依赖。





**实验 2 ： 数据集的 distance 之间的差异** 

Resnet18 是一个在 ImageNet1000 上训练的预训练模型 ，我们尝试使用和  ImageNet1000 差别较大的数据集进行实验对比 ，例如 domainnet 



**model reprogramming** 

|            | resnet18 |      |      |
| ---------- | -------- | ---- | ---- |
| quick_draw | 0.89     |      |      |
|            |          |      |      |
|            |          |      |      |



**实验 1**

**单源数据集去训练 resnet18 ， 然后用另一个单源数据集去微调。**

上游数据集(**Quickdraw**)  ，下游数据集(**Real**)

