# model reprogramming benchmark  实验报告



**注解** ： 

1. **linear-probe finetune** :  在原有模型的基础上 ，加上这个分类头来应用于目标任务 ， 我们的微调也只微调这个分类头 
2. **fully-fintune** ：更改模型所有层（替换分类头），侧重于更改模型所有参数
3. **fine-tune classification head** ：只修改最后一层并对其微调
4. **model reprogramming**：模型重编程



### 实验设计

该实验主要是从三个维度来探究 model reporgramming 和 finetune 方法的性能上的差异，探究 model reprogramming 在什么时候有作用 ，优势区间在哪 

1. 探究不同 数据集 size 下对模型微调，模型重编程的影响 

2. 探究数据集差异（distance）对model reprogramming的影响 

3. 探究噪声（noise） 对 model reprogramming 的影响 

   



Resnet18 实验结果

#### **实验1 ： 影响因素是数据集的大小**

**Cifar 10** 

*epoch 50 下训练，理论实际结果最佳可能有2%左右的浮动*

|                                   | 20%  | 40%  | 60%   | 80%  | 100% |
| --------------------------------- | ---- | ---- | ----- | ---- | ---- |
| **fully-fintune**                 | 92.7 | 94.0 | 94.7  | 95.1 | 95.6 |
| **fine-tune classification head** | 76.9 | 79.3 | 79.65 | 80.3 | 81.2 |
| **model reprogramming**           | 62.8 | 68.2 | 68.3  | 68.4 | 72.8 |
| **linear-probe finetune**         | 78.4 | 79.6 | 80.1  | 80.8 | 81.0 |

**Cifar100**

|                                   | 20%  | 40%  | 60%  | 80%  | 100%  |
| --------------------------------- | ---- | ---- | ---- | ---- | ----- |
| **fully-fintune**                 | 73.1 | 77.6 | 80.3 | 79.4 | 80.6  |
| **fine-tune classification head** | 50.2 | 55.2 | 57.8 | 58.8 | 59.74 |
| **model reprogramming**           | 32.1 | 34.7 | 35.7 | 36.6 | 39.4  |
| **linear-probe finetune**         | 52.8 | 56.8 | 58.0 | 59.1 | 60.0  |

**SVHN**

|                                   | 20%  | 40%  | 60%  | 80%   | 100% |
| --------------------------------- | ---- | ---- | ---- | ----- | ---- |
| **fully-fintune**                 |      |      |      |       |      |
| **fine-tune classification head** |      |      |      |       |      |
| **model reprogramming**           | 73.7 | 77.8 | 76.2 | 79.81 | 84.4 |
| **linear-probe finetune**         |      |      |      |       |      |



**vit_base_patch16_224**

**Cifar10**

|                                   | 20%  | 40%  | 60%  | 80%  | 100% |
| --------------------------------- | ---- | ---- | ---- | ---- | ---- |
| **fully-fintune**                 |      |      |      |      |      |
| **fine-tune classification head** |      |      |      |      |      |
| **model reprogramming**           |      |      | 68.6 | 89.4 |      |
| **linear-probe finetune**         |      |      |      |      |      |





- **CIFAR-10 上：**
  - Fully-finetune 一开始就有很高性能，受数据量影响较小。
  - Model reprogramming 对数据量**非常敏感**，提升最大。
  - Fine-tune head 和 linear-probe 表现稳定，但增益一般。
- **CIFAR-100 上：**
  - 所有方法对数据量都更敏感，提升都在 **7–9%** 区间。
  - “fine-tune classification head” 和 “model reprogramming” 提升幅度更大，说明它们对更大的训练数据更依赖。

Cifar 10

| 策略                  | 20% 准确率 | 100% 准确率 | 绝对提升 (%) | 相对提升 (%) |
| --------------------- | ---------- | ----------- | ------------ | ------------ |
| Fully-finetune        | 92.7       | 95.6        | **2.9**      | **3.13%**    |
| Fine-tune head        | 76.9       | 81.2        | **4.3**      | **5.59%**    |
| Model reprogramming   | 62.8       | 72.8        | **10.0**     | **15.92%**   |
| Linear-probe finetune | 78.4       | 81.0        | **2.6**      | **3.32%**    |

Cifar100

| 策略                  | 20% 准确率 | 100% 准确率 | 绝对提升 (%) | 相对提升 (%) |
| --------------------- | ---------- | ----------- | ------------ | ------------ |
| Fully-finetune        | 73.1       | 80.6        | **7.5**      | **10.26%**   |
| Fine-tune head        | 50.2       | 59.74       | **9.54**     | **19.00%**   |
| Model reprogramming   | 32.1       | 39.4        | **7.3**      | **22.74%**   |
| Linear-probe finetune | 52.8       | 60.0        | **7.2**      | **13.64%**   |







#### **实验 2 ： 数据集的 distance 之间的差异** 

**实验方法**

Resnet18 是一个在 ImageNet1000 上训练的预训练模型 ，我们尝试使用和  ImageNet1000 差别较大的数据集进行实验对比 ，例如 domainnet 

我们这里实验使用的是 “quickdraw” ，“real” ， “infograph“ ， ”Clipart” ， “Sketch”
这五个数据集 。**单源数据集去训练 resnet18 ， 然后用另一个单源数据集去微调或者mr。**基于磁盘空间的限制 ，我这里 上游选择了 30 类 去训练 resnet18 模型 ， 然后下游选取 10类去做 fft 和 mr 

![image-20250417023030934](G:/model%20reprogramming/model_reprogramming_benchmark/assets/image-20250417023030934.png)



Real 是真实物品的图片，其他的类别多少都保留了对象结构特征，按照数据集的差异我们可以计算出数据集之间的distance



**FID（Fréchet Inception Distance）**

对于距离计算，我这里使用的是 FID（Fréchet Inception Distance），这是一种衡量两个图像集合在特征空间中分布差异的指标，通常用于：

- 比较生成图像与真实图像的相似度（比如 GAN 评估）
- 比较不同风格（domain）图像之间的分布差距
- 衡量图像迁移/风格转换/重编程等任务中的 **domain gap**

因此它是很适合我们的实验任务的，FID 并不是直接对比图像像素，而是先使用一个预训练网络（通常是 Inception-v3）提取图像特征向量，然后对这些特征向量的分布做统计建模，再计算两个分布的“距离”。

计算方法：

1. 给两个图像集合 $X$ 和 $Y$，用预训练的 Inception-v3 模型提取每张图像的特征（比如 2048 维的向量）。
2. 对两个集合的特征分别估计它们的 **多维高斯分布参数**：
   - 平均向量 $\mu_x, \mu_y$
   - 协方差矩阵 $\Sigma_x, \Sigma_y$
3. 然后用 **Fréchet 距离（Wasserstein-2 距离）** 计算两个分布的距离：

$$
\text{FID}(X, Y) = \| \mu_x - \mu_y \|^2 + \text{Tr} \left( \Sigma_x + \Sigma_y - 2(\Sigma_x \Sigma_y)^{1/2} \right)
$$

这里遇到一个问题，就是 Source Domain 和 Target Domain 的不同图片种类，比如Real的 cup 和 infograph 的 cup ，他们的 FID是否差别很大？，这里我是直接做均值计算来衡量两个类的 distance 
$$
\text{FID}(S, T) = \text{FID'}(S, T)/N_{ClassNumber}
$$
例如 Real 和 Infograph 的 FID 均值是 197.53

​	quickdraw 和 real 的 FID 均值是 336.36 ， 因此 quickdraw 明显是 比 infograph 离 Real 远的 

|      | **quickdraw** | Infograph | sketch | clipart | painting |
| ---- | ------------- | --------- | ------ | ------- | -------- |
| real | 336.36        | 197.53    | 203.97 | 197.53  | 160.04   |



**Maximum Mean Discrepancy（最大均值差异）**

MMD 的核心思想是：

> **如果两个分布在某个特征空间中的所有函数上的期望值都相等，那么这两个分布就是相同的。**

MMD 就是通过计算两个样本在某个 **再生核希尔伯特空间（RKHS）** 中的**均值嵌入（mean embedding）之间的距离**，来判断它们是否来自同一个分布。

设有两个分布 $P$ 和 $Q$，从它们中采样出两个样本集合：

- $X = \{x_1, \dots, x_m\} \sim P$
- $Y = \{y_1, \dots, y_n\} \sim Q$

在一个带核函数 $k$ 的 RKHS $\mathcal{H}$ 中，MMD 的无偏估计可以表示为：
$$
\text{MMD}^2(X, Y) = \frac{1}{m(m-1)} \sum_{i \neq j} k(x_i, x_j) + \frac{1}{n(n-1)} \sum_{i \neq j} k(y_i, y_j) - \frac{2}{mn} \sum_{i, j} k(x_i, y_j)
$$
其中 $k(x, y)$ 常用的是 **Gaussian 核函数** 或 **多项式核函数**：
$$
k(x, y) = \exp\left(-\frac{\|x - y\|^2}{2\sigma^2}\right)
$$


|      | **quickdraw** | Infograph | sketch | clipart | painting |
| ---- | ------------- | --------- | ------ | ------- | -------- |
| real | 0.0042        | 0.0139    | 0.0112 | 0.0134  | 0.0117   |

MMD 距离结论是 ：quickdraw < sketch < painting < clipart < Infograph （distance to real）

FID 距离结论是 ：painting < clipart = infograph < sketch < quickdraw (distance to real)

如果只以数量级来看的话 对 MMD 来说明显差异大的只有 quickdraw ，(sketch，painting) 基本上一样 ，（clipart，infograph） 结果一样 

对于 FID 距离 quickdraw 距离最远 ，painting 最近 ，其余三个差异不算大 。这点比较符合我们的直观感受，因此我觉得 **FID 是更可靠的距离计算方式**





**实验结果**

| upstream  | downstream | Train | MR   | FFT  |
| --------- | ---------- | ----- | ---- | ---- |
| quickdraw | Real       | 80.2  | 53.7 | 66.0 |
| Sketch    | Real       | 33.2  | 59.7 | 72.9 |
| Quckdraw  | Real       | 86.0  | 64.9 | 80.1 |
| Clipart   | Real       | 52.8  | 68.7 | 79.7 |
| Infograph | Real       | 23.2  | 56.5 | 72.9 |
| Painting  | Real       | 37.6  | 61.9 | 71.0 |
| Real      | Sketch     | 75.8  | 41.2 | 50.6 |
| Real      | quickdraw  | 75.8  | 77.0 | 87.9 |
| Real      | clipart    | 75.8  | 47.8 | 62.1 |
| Real      | infograph  | 75.8  | 31.1 | 42.5 |
| Real      | painting   | 74.9  | 39.0 | 55.6 |



**实验分析**

一、**向 Real 的迁移（下游为 Real）**

- 向 Real 迁移时，**clipart** 的 MR 最高（68.7），重编程效果最好。

- **quickdraw** FID 虽大，但其迁移效果好，说明 Real 能够从其学到鲁棒特征。

- MR 和 FFT 在这组中 **一致偏高**，表明从其他子域迁移到 Real 相对容易。

二，**向 domainnet 域的迁移**

- **在 Real → X 的迁移中，MR 与 FID 呈“非单调弱相关”**：高 FID 不一定带来低 MR。

  **quickdraw 是最容易通过模型重编程迁移的目标域**，尽管其分布差异最大，表明：

  - 模型重编程不依赖视觉近似
  - 更依赖图像语义结构是否“可映射”

  **infograph 是最难迁移的目标域**，说明它在语义空间中与 real 差异较大。



三，**整体分析**

##### **Real → X** 

###### 1. **整体趋势对比：MR vs FFT**

- 大多数迁移方向上，**FFT > MR**，说明微调在充分数据下表现更强；
- 但在 **某些高分布距离对**中，MR 表现接近甚至优于 FFT，这体现出 **重编程在低资源/大分布差异迁移中的潜力**。

###### 2. **逐方向分析差值（FFT - MR）**



| 迁移方向         | MR   | FFT  | FID (`real→ target`) | Δ = FFT - MR | 分析                                                         |
| ---------------- | ---- | ---- | -------------------- | ------------ | ------------------------------------------------------------ |
| Real → quickdraw | 77.0 | 87.9 | 336.36               | **+10.9**    | 分布距离最大，FFT 虽更强，但 MR 保持较高性能，显示其在极端分布偏移下的迁移鲁棒性。 |
| Real → sketch    | 41.2 | 50.6 | 203.97               | **+9.4**     | sketch 风格独特，分布差异中等，FFT 略优但 MR 差距较小，表现较稳。 |
| Real → clipart   | 47.8 | 62.1 | 197.53               | **+14.3**    | 分布差异中等，FFT 获得明显提升，MR 相对劣势较大，可能因结构特征差异难以适应。 |
| Real → infograph | 31.1 | 42.5 | 197.53               | **+11.4**    | 迁移难度最高任务之一，MR 效果受限，FFT 相对更能适应图文混合结构的目标域。 |
| Real → painting  | 39.0 | 55.6 | 160.04               | **+16.6**    | 虽为视觉风格最接近的目标域，FFT 显著优于 MR，表明在可微调条件下更易受益，而 MR 表现受限。 |

###### 3. **是否有 MR 更优的方向？**

在目前这张表中，**FFT 全部优于 MR**，但**优势幅度有限（最大也只有十几个点）**，说明：

> 虽然 fine-tuning 整体表现更强，但 MR 的表现也具有一定竞争力，尤其在 quickdraw 这种“分布极远 + 图像风格极端”的目标域中，MR 能保持 77.0 的性能，是非常不错的迁移基线。

**实验结论**：**在源域与目标域存在较大分布差异的迁移任务中，MR 方法的性能相对微调（FFT）更加接近，表现出更强的跨域鲁棒性。**

##### **X → Real** 

| Upstream  | FID (`source → real`) | MR   | FFT  | Δ = FFT - MR     |
| --------- | --------------------- | ---- | ---- | ---------------- |
| quickdraw | **336.36**            | 53.7 | 66.0 | **12.3**         |
| sketch    | 203.97                | 59.7 | 72.9 | **13.2**         |
| clipart   | 197.53                | 68.7 | 79.7 | **11.0**         |
| infograph | 197.53                | 56.5 | 72.9 | **16.4（最大）** |
| painting  | 160.04                | 61.9 | 71.0 | 10.1             |

- 在 FID 最大的 **quickdraw → real** 中，MR 与 FFT 的差距是 **12.3**；
- 在 FID 中等的 **clipart → real** 中，差距 **最小**（11.0）；
- 在 FID 接近但视觉结构差异大的 **infograph → real** 中，MR 和 FFT 差距最大（16.4）；
- 整体来看，“分布差异越大 → MR 趋近于 FFT”的结论在这个方向**仍然部分成立**，但**不如 real → other 的趋势明显和线性**。

**在其他子域迁移至 real 的任务中，MR 与 FFT 的性能差距仍与分布距离有关，但趋势不如 real → other 明显。**
 尤其在 infograph → real 迁移中，即使分布距离与 clipart 相近，MR 与 FFT 的差距却最大，说明此时 MR 表征能力可能受到限制。
 然而，在 quickdraw/sketch 等强偏移源域中，MR 的稳定性再次体现，使其在迁移距离极大时依然具有一定优势。





本实验评估了模型重编程（Model Reprogramming）在跨域场景中的表现，重点关注从**非真实图像域（如 Quickdraw、Sketch、Clipart、Infograph、Painting）**迁移至**真实图像域（Real）**的效果。

从表中结果来看：

- 当上游为 **Quickdraw、Clipart、Sketch、Infograph、Painting**，下游为 **Real** 时，模型在 MR 指标上取得了较为显著的性能，**平均 MR 达到 61.9**，显示出模型在该方向具备较强的迁移适应能力。

- 最佳表现来自 **Clipart → Real**，其 MR 值为 **68.7**，其次为 **Quickdraw → Real**（64.9）和 **Painting → Real**（61.9），说明从风格化或抽象化图像迁移到真实图像时，模型能够较好地提取通用语义特征。

- 尽管上游数据具有较大的风格差异，如手绘风（Sketch）、图标风（Infograph），模型依然能通过重编程学到有效的适配模式，体现出一定的鲁棒性。

与之对比，**从 Real 域迁移到非真实图像域**时的 MR 值整体偏低（如 Real → Infograph 为 31.1，Real → Clipart 为 47.8），说明该方向的迁移更具挑战性。

因此，实验结果表明：

​	模型重编程在“从非真实图像域迁移到真实图像域”方向表现出更强的跨域适应能力。这表明重编程机制有助于将抽象风格图像中的底层语义特征映射至更结构化的真实图像表示，从而提升分类性能。













#### 实验 3 ：噪声对model reporgramming 的影响 

**Resnet18**

|          | MR(with Gaussion noise) | MR(with blur noise) | MR(with salt paper noise) | MR   | FFT  |
| -------- | ----------------------- | ------------------- | ------------------------- | ---- | ---- |
| Cifar10  | 59.8                    | 65.6                | 64.0                      | 72.8 | 83.4 |
| Cifar100 | 15.6                    | 16.5                |                           | 39.4 | 57.9 |
| SVHN     | 87.3                    | 88.0                | 82.8                      | 84.4 | 93.6 |



**Vit** 

|          | MR(with Gaussion noise) | MR(with blur noise) | MR(with salt paper noise) | MR   | FFT  |
| -------- | ----------------------- | ------------------- | ------------------------- | ---- | ---- |
| Cifar10  |                         |                     |                           |      |      |
| Cifar100 |                         |                     |                           |      |      |
| SVHN     |                         |                     |                           |      |      |
