# model reprogramming benchmark  实验报告



**注解** ： 

1. **linear-probe finetune** :  在原有模型的基础上 ，加上这个分类头来应用于目标任务 ， 我们的微调也只微调这个分类头 
2. **fully-fintune** ：更改模型所有层（替换分类头），侧重于更改模型所有参数
3. **fine-tune classification head** ：只修改最后一层并对其微调
4. **model reprogramming**：模型重编程



### 实验设计

该实验主要是从三个维度来探究 model reporgramming 和 finetune 方法的性能上的差异，探究 model reprogramming 在什么时候有作用 ，优势区间在哪 

1. 探究不同 数据集 size 下对模型微调，模型重编程的影响 

2. 探究数据集差异（distance）对model reprogramming的影响 

3. 探究噪声（noise） 对 model reprogramming 的影响 

   



### Resnet18 实验结果

**实验1 ： 影响因素是数据集的大小**

**Cifar 10** 

*epoch 50 下训练，理论实际结果最佳可能有2%左右的浮动*

|                                   | 20%  | 40%  | 60%   | 80%  | 100% |
| --------------------------------- | ---- | ---- | ----- | ---- | ---- |
| **fully-fintune**                 | 92.7 | 94.0 | 94.7  | 95.1 | 95.6 |
| **fine-tune classification head** | 76.9 | 79.3 | 79.65 | 80.3 | 81.2 |
| **model reprogramming**           | 62.8 | 68.2 | 68.3  | 68.4 | 72.8 |
| **linear-probe finetune**         | 78.4 | 79.6 | 80.1  | 80.8 | 81.0 |

**Cifar100**

|                                   | 20%  | 40%  | 60%  | 80%  | 100%  |
| --------------------------------- | ---- | ---- | ---- | ---- | ----- |
| **fully-fintune**                 | 73.1 | 77.6 | 80.3 | 79.4 | 80.6  |
| **fine-tune classification head** | 50.2 | 55.2 | 57.8 | 58.8 | 59.74 |
| **model reprogramming**           | 32.1 | 34.7 | 35.7 | 36.6 | 39.4  |
| **linear-probe finetune**         | 52.8 | 56.8 | 58.0 | 59.1 | 60.0  |



**SVHN**

|                                   | 20%  | 40%  | 60%  | 80%   | 100% |
| --------------------------------- | ---- | ---- | ---- | ----- | ---- |
| **fully-fintune**                 |      |      |      |       |      |
| **fine-tune classification head** |      |      |      |       |      |
| **model reprogramming**           | 73.7 | 77.8 | 76.2 | 79.81 | 84.4 |
| **linear-probe finetune**         |      |      |      |       |      |



- **CIFAR-10 上：**
  - “model reprogramming” 对数据量最敏感，增长了 **10%**。
  - “fully-finetune” 和 “linear-probe finetune” 的提升都在 **3% 左右**，说明它们更稳定。
- **CIFAR-100 上：**
  - 所有方法对数据量都更敏感，提升都在 **7–9%** 区间。
  - “fine-tune classification head” 和 “model reprogramming” 提升幅度更大，说明它们对更大的训练数据更依赖。





**实验 2 ： 数据集的 distance 之间的差异** 

**实验方法**

Resnet18 是一个在 ImageNet1000 上训练的预训练模型 ，我们尝试使用和  ImageNet1000 差别较大的数据集进行实验对比 ，例如 domainnet 

我们这里实验使用的是 “quickdraw” ，“real” ， “infograph“ ， ”Clipart” ， “Sketch”
这五个数据集 。**单源数据集去训练 resnet18 ， 然后用另一个单源数据集去微调或者mr。**基于磁盘空间的限制 ，我这里 上游选择了 30 类 去训练 resnet18 模型 ， 然后下游选取 10类去做 fft 和 mr 

![image-20250417023030934](G:/model%20reprogramming/model_reprogramming_benchmark/assets/image-20250417023030934.png)



Real 是真实物品的图片，其他的类别多少都保留了对象结构特征，按照数据集的差异我们可以计算出数据集之间的distance

对于距离计算，我这里使用的是 FID（Fréchet Inception Distance），这是一种衡量两个图像集合在特征空间中分布差异的指标，通常用于：

- 比较生成图像与真实图像的相似度（比如 GAN 评估）
- 比较不同风格（domain）图像之间的分布差距
- 衡量图像迁移/风格转换/重编程等任务中的 **domain gap**

因此它是很适合我们的实验任务的，FID 并不是直接对比图像像素，而是先使用一个预训练网络（通常是 Inception-v3）提取图像特征向量，然后对这些特征向量的分布做统计建模，再计算两个分布的“距离”。

计算方法：

1. 给两个图像集合 $X$ 和 $Y$，用预训练的 Inception-v3 模型提取每张图像的特征（比如 2048 维的向量）。
2. 对两个集合的特征分别估计它们的 **多维高斯分布参数**：
   - 平均向量 $\mu_x, \mu_y$
   - 协方差矩阵 $\Sigma_x, \Sigma_y$
3. 然后用 **Fréchet 距离（Wasserstein-2 距离）** 计算两个分布的距离：

$$
\text{FID}(X, Y) = \| \mu_x - \mu_y \|^2 + \text{Tr} \left( \Sigma_x + \Sigma_y - 2(\Sigma_x \Sigma_y)^{1/2} \right)
$$

这里遇到一个问题，就是 Source Domain 和 Target Domain 的不同图片种类，比如Real的 cup 和 infograph 的 cup ，他们的 FID是否差别很大？，这里我是直接做均值计算来衡量两个类的 distance 
$$
\text{FID}(S, T) = \text{FID'}(S, T)/N_{ClassNumber}
$$
例如 Real 和 Infograph 的 FID 均值是 197.53

​	quickdraw 和 real 的 FID 均值是 336.36 ， 因此 quickdraw 明显是 比 infograph 离 Real 远的 

|      | **quickdraw** | Infograph | sketch | clipart | painting |
| ---- | ------------- | --------- | ------ | ------- | -------- |
| real | 336.36        | 197.53    | 203.97 |         |          |





**model reprogramming**

**上游(Quickdraw)**

![image-20250409163959468](G:/model%20reprogramming/model_reprogramming_benchmark/assets/image-20250409163959468.png)



**下游(Real)**

<img src="G:/model%20reprogramming/model_reprogramming_benchmark/assets/image-20250409163221044.png" alt="image-20250409163221044" style="zoom: 80%;" />



**fully fintune**

![image-20250409181212178](G:/model%20reprogramming/model_reprogramming_benchmark/assets/image-20250409181212178.png)



上游基于Sketch的训练结果是 86 % ，下游mr 的结果是 65% ，下游 ft的结果是 80% 左右。



后续数据以表格形式整理 



| upperstream,downstream | Train | MR   | FFT  |
| ---------------------- | ----- | ---- | ---- |
| quickdraw,Real         | 86.0  | 65.1 | 80.1 |
| Sketch，Real           | 46.1  | 63.3 | 79.9 |
| Quckdraw , Real        | 86.0  | 64.9 | 80.1 |
| Clipart , Real         | 52.8  | 68.7 | 79.7 |
| Inforgraph , Real      | 23.2  | 56.5 | 72.9 |
| Real , Sketch          | 75.8  | 63.6 | 71.4 |
| Real,quickdraw         | 75.8  | 74.0 | 87.9 |
| Real , clipart         | 75.8  | 45.2 | 62.1 |
| Real, infograph        | 75.8  | 26.0 | 42.5 |

