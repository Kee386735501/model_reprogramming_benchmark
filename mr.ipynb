{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "!pip install numpy\n",
    "\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet18, ResNet18_Weights, resnet50, ResNet50_Weights\n",
    "from torch.utils.data import DataLoader, Subset  # 修正：导入 Subset\n",
    "import numpy as np\n",
    "# dataset and dataloader\n",
    "def get_dataloaders(dataset_name=\"cifar10\", batch_size=64, num_workers=2,train_ratio=1.0):\n",
    "    if dataset_name.lower() == \"cifar10\":\n",
    "        num_classes = 10\n",
    "        transform_train = transforms.Compose([\n",
    "            transforms.Resize(224),\n",
    "            transforms.RandomCrop(224, padding=4),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                                 (0.2470, 0.2435, 0.2616)),\n",
    "        ])\n",
    "        transform_test = transforms.Compose([\n",
    "            transforms.Resize(224),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                                 (0.2470, 0.2435, 0.2616)),\n",
    "        ])\n",
    "        train_dataset = torchvision.datasets.CIFAR10(\n",
    "            root=\"./data\",\n",
    "            train=True,\n",
    "            download=True,\n",
    "            transform=transform_train\n",
    "        )\n",
    "        test_dataset = torchvision.datasets.CIFAR10(\n",
    "            root=\"./data\",\n",
    "            train=False,\n",
    "            download=True,\n",
    "            transform=transform_test\n",
    "        )\n",
    "    elif dataset_name.lower() == \"cifar100\":\n",
    "        num_classes = 100\n",
    "        transform_train = transforms.Compose([\n",
    "            transforms.Resize(224),\n",
    "            transforms.RandomCrop(224, padding=4),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
    "        ])\n",
    "        transform_test = transforms.Compose([\n",
    "            transforms.Resize(224),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
    "        ])\n",
    "        train_dataset = torchvision.datasets.CIFAR100(\n",
    "            root=\"./data\",\n",
    "            train=True,\n",
    "            download=True,\n",
    "            transform=transform_train\n",
    "        )\n",
    "        test_dataset = torchvision.datasets.CIFAR100(\n",
    "            root=\"./data\",\n",
    "            train=False,\n",
    "            download=True,\n",
    "            transform=transform_test\n",
    "        )\n",
    "    else:\n",
    "        raise NotImplementedError(f\"Dataset {dataset_name} not supported yet.\")\n",
    "\n",
    "    # 选择部分训练数据\n",
    "    num_train_samples = int(len(train_dataset) * train_ratio)  # 计算需要的样本数量\n",
    "    train_indices = np.random.choice(len(train_dataset), num_train_samples, replace=False)  # 随机选取索引\n",
    "    train_subset = Subset(train_dataset, train_indices)  # 创建子集\n",
    "\n",
    "    train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "    return train_loader, test_loader, num_classes\n",
    "\n",
    "\n",
    "def get_model(model_name=\"resnet18\", num_classes=10, device=\"cpu\"):\n",
    "    model_name = model_name.lower()\n",
    "    if model_name == \"resnet18\":\n",
    "        model = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "        in_features = model.fc.in_features\n",
    "        model.fc = nn.Linear(in_features, num_classes)\n",
    "    elif model_name == \"resnet50\":\n",
    "        model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\n",
    "        in_features = model.fc.in_features\n",
    "        model.fc = nn.Linear(in_features, num_classes)\n",
    "    else:\n",
    "        raise NotImplementedError(f\"Model {model_name} not supported yet.\")\n",
    "\n",
    "    return model.to(device)\n",
    "\n",
    "###############################\n",
    "# 训练与测试的函数\n",
    "###############################\n",
    "def train_one_epoch(model, train_loader, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    loop = tqdm(train_loader, desc=\"Training\", leave=True)  # ✅ 添加 tqdm\n",
    "    for inputs, labels in loop:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        # ✅ 在 tqdm 进度条中更新信息\n",
    "        loop.set_postfix(loss=loss.item(), acc=100.0 * correct / total)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = 100.0 * correct / total\n",
    "\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "# 测试函数（添加 tqdm 进度条）\n",
    "def test_one_epoch(model, test_loader, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    loop = tqdm(test_loader, desc=\"Testing\", leave=True)  # ✅ 添加 tqdm\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loop:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = F.cross_entropy(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "            # ✅ 更新 tqdm 进度条信息\n",
    "            loop.set_postfix(loss=loss.item(), acc=100.0 * correct / total)\n",
    "\n",
    "    epoch_loss = running_loss / len(test_loader)\n",
    "    epoch_acc = 100.0 * correct / total\n",
    "\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_results(csv_filename):\n",
    "    \"\"\"\n",
    "    从csv_filename读取 epoch, train_loss, train_acc, test_loss, test_acc，\n",
    "    分别画出Loss曲线和Accuracy曲线。\n",
    "    \"\"\"\n",
    "    # 读取CSV\n",
    "    df = pd.read_csv(csv_filename)\n",
    "\n",
    "    # 提取列\n",
    "    epochs = df['epoch']\n",
    "    train_loss = df['train_loss']\n",
    "    test_loss = df['test_loss']\n",
    "    train_acc = df['train_acc']\n",
    "    test_acc = df['test_acc']\n",
    "\n",
    "    # 画Loss曲线\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, train_loss, label=\"Train Loss\")\n",
    "    plt.plot(epochs, test_loss, label=\"Test Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Loss over Epochs\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # 画Accuracy曲线\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, train_acc, label=\"Train Acc\")\n",
    "    plt.plot(epochs, test_acc, label=\"Test Acc\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy (%)\")\n",
    "    plt.title(\"Accuracy over Epochs\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "###############################\n",
    "# 主函数\n",
    "###############################\n",
    "def main():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using device:\", device)\n",
    "\n",
    "    # ============= 切换数据集和模型 =============\n",
    "    dataset_name = \"cifar10\"  # \"cifar10\", \"cifar100\"\n",
    "    model_name = \"resnet50\"   # \"resnet18\", \"resnet50\"\n",
    "    # ===========================================\n",
    "\n",
    "    train_loader, test_loader, num_classes = get_dataloaders(dataset_name=dataset_name)\n",
    "    model = get_model(model_name=model_name,\n",
    "                      num_classes=num_classes,\n",
    "                      device=device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "    # 准备一个 CSV 文件来保存结果\n",
    "    # 如果你想追加写入，可以改成 'a'; 这里我们先用 'w' 重写。\n",
    "    csv_filename = f\"results_{dataset_name}_{model_name}.csv\"\n",
    "    with open(csv_filename, mode='w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        # 写标题行\n",
    "        writer.writerow([\"epoch\", \"train_loss\", \"train_acc\", \"test_loss\", \"test_acc\"])\n",
    "\n",
    "        EPOCHS = 50\n",
    "        best_acc = 0.0\n",
    "        for epoch in range(1, EPOCHS+1):\n",
    "            start_time = time.time()\n",
    "            train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, device)\n",
    "            test_loss, test_acc = test_one_epoch(model, test_loader, device)\n",
    "            epoch_time = time.time() - start_time\n",
    "\n",
    "            # 打印日志\n",
    "            print(f\"[Epoch {epoch:02d}] \"\n",
    "                  f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}% | \"\n",
    "                  f\"Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.2f}% | \"\n",
    "                  f\"Time: {epoch_time:.2f}s\")\n",
    "\n",
    "            # 写入 CSV\n",
    "            writer.writerow([epoch, train_loss, train_acc, test_loss, test_acc])\n",
    "\n",
    "            # 保存最优模型\n",
    "            if test_acc > best_acc:\n",
    "                best_acc = test_acc\n",
    "                torch.save(model.state_dict(), f\"best_{dataset_name}_{model_name}.pth\")\n",
    "\n",
    "    print(f\"Training finished! Best Test Acc={best_acc:.2f}%\")\n",
    "    print(f\"Results have been saved to {csv_filename}\")\n",
    "    # =============== 训练结束，开始绘图 ===============\n",
    "    plot_results(csv_filename)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
