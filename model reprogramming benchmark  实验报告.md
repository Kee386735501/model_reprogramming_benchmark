# model reprogramming benchmark  实验报告



 **Part 1 实验目的说明**

本实验旨在系统评估 Model Reprogramming（模型重编程）在不同应用条件下的表现，并与传统微调方法（如全量微调、线性探针）进行对比分析。重点探索以下三个方面：

1. **在数据量不同的条件下**，模型重编程相较微调方法的性能变化趋势；
2. **在存在较大 domain gap 的跨域场景中**，模型重编程能否有效迁移；
3. **在输入图像加入不同噪声干扰的情况下**，模型重编程方法的鲁棒性如何。

通过以上对比，旨在明确模型重编程的**适用范围、优势场景与性能边界**，为后续在低资源、跨域应用等方向的模型迁移提供参考依据。



| 方法名称                  | 简要说明                                                     | 是否训练主干模型 |
| ------------------------- | ------------------------------------------------------------ | ---------------- |
| **Fully Finetune**        | 替换分类头，然后对整个模型（包括主干网络和分类头）进行全参数微调 | ✅ 是             |
| **Linear-probe Finetune** | 在原模型特征上训练一个独立分类器（线性层），主干冻结         | ❌ 否             |
| **Model Reprogramming**   | 模型重编程方法（基于SMM那篇论文）                            | ❌ 否             |











#### **实验 1：数据集规模对模型表现的影响**

本实验旨在评估四种方法在**训练数据比例不同**的条件下（20% - 100%）的表现，探索它们对数据规模的敏感性。



**实验方法** 

模型采用的是图像分类最常见的 Resnet18 ，数据集采取了三个 svhn ,  cifar-10 , cifar-100 ,  数据集的 size 选取从 [0.2 , 0.4 , 0.6 , 0.8 ,1.0] ，测试集不做变化

从难易度上来讲 svhn  < cifar-10 < cifar-100 ,   分别为10类，10类 ，100类

从参数量的角度来说 model reprogramming 训练参数多于 Linear Probe ，但是整个来说二者都小于全参数微调

| 模型                | 全参数微调量级 | 参数总量  |
| ------------------- | -------------- | --------- |
| ResNet18            | 中等           | **11.7M** |
| ViT-B/16            | 非常大         | **85.8M** |
| Linear Probe        | 很小           | ~**100K** |
| Model Reprogramming | 中等偏大       | ~**180K** |







**CIFAR-10 / ResNet18 结果**

|                           | 20%  | 40%  | 60%  | 80%  | 100%     | 每 10% 提升 |
| ------------------------- | ---- | ---- | ---- | ---- | -------- | ----------- |
| **fully-fintune**         | 92.7 | 94.0 | 94.7 | 95.1 | **95.6** | 0.36%       |
| **model reprogramming**   | 62.8 | 68.2 | 68.3 | 68.4 | 72.8     | **1.25%**   |
| **linear-probe finetune** | 78.4 | 79.6 | 80.1 | 80.8 | 81.0     | 0.13%       |

**观察与分析：**

- **Fully Finetune** 从一开始就能获得较高的准确率，表现最稳定，对数据量的敏感性最低，适合小数据量下的精调场景；

- **Model Reprogramming** 对数据量最敏感，准确率从 62.8 提升到 72.8，**平均每 10% 提升约 1.25%**，远高于其他方法；

- **Linear-probe** 整体表现稳定，精度略高于 reprogramming，但提升幅度有限，增长趋于饱和；

- 从整体趋势来看，fully-finetune 的效果最佳，其次为 linear-probe，而 model reprogramming 当前准确率最低；

- **Model Reprogramming 方法在数据量增加时表现出显著提升，说明其在大规模数据场景下仍具备优化空间，有望进一步提高准确率。**





**CIFAR-100 / ResNet18 结果**

|                           | 20%  | 40%  | 60%  | 80%  | 100%     | 每 10% 提升 |
| ------------------------- | ---- | ---- | ---- | ---- | -------- | ----------- |
| **fully-fintune**         | 73.1 | 77.6 | 80.3 | 79.4 | **80.6** | **0.94%**   |
| **model reprogramming**   | 32.1 | 34.7 | 35.7 | 36.6 | 39.4     | 0.91%       |
| **linear-probe finetune** | 52.8 | 56.8 | 58.0 | 59.1 | 60.0     | 0.90%       |

**观察与分析：**

- 相比 CIFAR-10，**CIFAR-100 的分类难度更大，所有方法对数据量均更敏感**，体现为准确率整体较低但提升幅度更大；

- **Fully Finetune 的每 10% 数据增量带来的收益最大（0.94）**，在 100 类任务中展现出更强的拟合能力；

- **Model Reprogramming 方法虽然提升幅度也较大（0.91），但整体准确率偏低**，说明其在大类别场景中相对较弱；

- Linear-probe 的表现居中，最终准确率略高于 reprogramming，但提升幅度略小（0.90）；

  



**SVHN / ResNet18 结果**

|                           | 20%  | 40%  | 60%  | 80%   | 100%     | 每 10% 提升 |
| ------------------------- | ---- | ---- | ---- | ----- | -------- | ----------- |
| **fully-fintune**         | 89.4 | 94.4 | 94.8 | 94.1  | **98.3** | 2.22        |
| **model reprogramming**   | 73.7 | 77.8 | 76.2 | 79.81 | 84.4     | **2.68**    |
| **linear-probe finetune** | 40.7 | 41.7 | 42.0 | 41.8  | 44.4     | 0.88        |

- Model Reprogramming 的平均增幅最大 , **对数据量增加最敏感**  
- **Linear-probe finetune** 的表现始终偏低，准确率从 **40.7% 仅增长至 44.2%**，几乎无明显提升
- **Fully Finetune** 方法表现最为优异，20% 数据下就已达 **89.4%** 准确率，且在满数据下进一步提升至 **98.3%**，呈现出极强的拟合能力和稳定增长；





**结论**

**Fully-finetune 在所有数据集上都表现最佳，但增益速率不同**

- **SVHN** 上提升最快（每 10% 提升约 **2.22%**），说明该任务对数据量敏感，模型能迅速受益于更多数据。
- **CIFAR-100** 的提升幅度也不错（**0.94%**），可能因类别多，训练复杂。
- **CIFAR-10** 的提升最慢（**0.36%**），说明在较少数据时模型已学到大部分判别特征。

------

**2. Model Reprogramming 增益率总体最高**

- 尽管其在所有数据比例下的准确率低于 fully-finetune，但它在 **每 10% 的数据提升带来的增益**上，尤其在 **SVHN（2.68%）和 CIFAR-10（1.25%）** 上表现 **最敏感**。
- 说明 model reprogramming 方法在小数据量下可能欠拟合严重，但随着数据增加提升迅速，适合在数据可渐进获取的场景中使用。

------

**3. Linear-probe finetune 增益最小，且准确率始终居中**

- 该方法在三个数据集上表现都比较稳定，但也说明它对数据扩展的利用能力有限（如 SVHN 仅 0.88% 提升）。
- 更适用于数据较少、对训练资源要求较低的情况，但难以进一步逼近 fully-finetune 的上限。



**总体趋势总结**

| 方法                      | 初始性能（低数据） | 每 10% 增益率 | 高数据性能（上限） | 适用场景                     |
| ------------------------- | ------------------ | ------------- | ------------------ | ---------------------------- |
| **Fully-finetune**        | 高                 | 中或高        | 最高               | 数据足够时优选               |
| **Model Reprogramming**   | 低或中             | **最高**      | 中                 | 渐进式数据增长，或资源受限时 |
| **Linear-probe Finetune** | 中                 | 最低          | 低或中             | 快速部署，低资源场景         |









#### **实验 2 ： 数据集的 distance 之间的差异** 

**实验方法**

Resnet18 是一个在 ImageNet1000 上训练的预训练模型 ，我们尝试使用和  ImageNet1000 差别较大的数据集进行实验对比 ，例如 domainnet 

我们这里实验使用的是 “quickdraw” ，“real” ， “infograph“ ， ”Clipart” ， “Sketch”
这五个数据集 。**单源数据集去训练 resnet18 ， 然后用另一个单源数据集去微调或者mr。**基于磁盘空间的限制 ，我这里 上游随机选择了 30 类 去训练 resnet18 模型 ， 然后下游选取 10类去做 fft 和 mr 

![image-20250417023030934](G:/model%20reprogramming/model_reprogramming_benchmark/assets/image-20250417023030934.png)



Real 是真实物品的图片，其他的类别多少都保留了对象结构特征但是属于抽象化，domain 跨度比较大，按照数据集的差异我们可以计算出数据集之间的distance



**FID（Fréchet Inception Distance）**

对于距离计算，我这里使用的是 FID（Fréchet Inception Distance），这是一种衡量两个图像集合在特征空间中分布差异的指标，通常用于：

- 比较生成图像与真实图像的相似度（比如 GAN 评估）
- 比较不同风格（domain）图像之间的分布差距
- 衡量图像迁移/风格转换/重编程等任务中的 **domain gap**

因此它是很适合我们的实验任务的，FID 并不是直接对比图像像素，而是先使用一个预训练网络（通常是 Inception-v3）提取图像特征向量，然后对这些特征向量的分布做统计建模，再计算两个分布的“距离”。

计算方法：

1. 给两个图像集合 $X$ 和 $Y$，用预训练的 Inception-v3 模型提取每张图像的特征（比如 2048 维的向量）。
2. 对两个集合的特征分别估计它们的 **多维高斯分布参数**：
   - 平均向量 $\mu_x, \mu_y$
   - 协方差矩阵 $\Sigma_x, \Sigma_y$
3. 然后用 **Fréchet 距离（Wasserstein-2 距离）** 计算两个分布的距离：

$$
\text{FID}(X, Y) = \| \mu_x - \mu_y \|^2 + \text{Tr} \left( \Sigma_x + \Sigma_y - 2(\Sigma_x \Sigma_y)^{1/2} \right)
$$

这里遇到一个问题，就是 Source Domain 和 Target Domain 的不同图片种类，比如Real的 cup 和 infograph 的 cup ，他们的 FID是否差别很大？，这里我是直接做均值计算来衡量两个类的 distance 
$$
\text{FID}(S, T) = \text{FID'}(S, T)/N_{ClassNumber}
$$
例如 Real 和 Infograph 的 FID 均值是 197.53

​	quickdraw 和 real 的 FID 均值是 336.36 ， 因此 quickdraw 明显是 比 infograph 离 Real 远的 

|      | **quickdraw** | Infograph | sketch     | clipart | painting |
| ---- | ------------- | --------- | ---------- | ------- | -------- |
| real | 336.36        | 197.53    | **203.97** | 197.53  | 160.04   |



**Maximum Mean Discrepancy（最大均值差异）**

MMD 的核心思想是：

> **如果两个分布在某个特征空间中的所有函数上的期望值都相等，那么这两个分布就是相同的。**

MMD 就是通过计算两个样本在某个 **再生核希尔伯特空间（RKHS）** 中的**均值嵌入（mean embedding）之间的距离**，来判断它们是否来自同一个分布。

设有两个分布 $P$ 和 $Q$，从它们中采样出两个样本集合：

- $X = \{x_1, \dots, x_m\} \sim P$
- $Y = \{y_1, \dots, y_n\} \sim Q$

在一个带核函数 $k$ 的 RKHS $\mathcal{H}$ 中，MMD 的无偏估计可以表示为：
$$
\text{MMD}^2(X, Y) = \frac{1}{m(m-1)} \sum_{i \neq j} k(x_i, x_j) + \frac{1}{n(n-1)} \sum_{i \neq j} k(y_i, y_j) - \frac{2}{mn} \sum_{i, j} k(x_i, y_j)
$$
其中 $k(x, y)$ 常用的是 **Gaussian 核函数** 或 **多项式核函数**：
$$
k(x, y) = \exp\left(-\frac{\|x - y\|^2}{2\sigma^2}\right)
$$


|      | **quickdraw** | Infograph  | sketch | clipart | painting |
| ---- | ------------- | ---------- | ------ | ------- | -------- |
| real | 0.0042        | **0.0139** | 0.0112 | 0.0134  | 0.0117   |

MMD 距离结论是 ：quickdraw < sketch < painting < clipart < Infograph （distance to real）

FID 距离结论是 ：painting < clipart = infograph < sketch < quickdraw (distance to real)

如果只以数量级来看的话 对 MMD 来说明显差异大的只有 quickdraw ，(sketch，painting) 基本上一样 ，（clipart，infograph） 结果一样 

对于 FID 距离 quickdraw 距离最远 ，painting 最近 ，其余三个差异不算大 。这点比较符合我们的直观感受，因此我觉得 **FID 是更可靠的距离计算方式**





**实验结果**

| upstream  | downstream | Train | MR       | FFT  |
| --------- | ---------- | ----- | -------- | ---- |
| quickdraw | Real       | 80.2  | 53.7     | 66.0 |
| Sketch    | Real       | 33.2  | 59.7     | 72.9 |
| Quckdraw  | Real       | 86.0  | 64.9     | 80.1 |
| Clipart   | Real       | 52.8  | **68.7** | 79.7 |
| Infograph | Real       | 23.2  | 56.5     | 72.9 |
| Painting  | Real       | 37.6  | 61.9     | 71.0 |
| Real      | Sketch     | 75.8  | 41.2     | 50.6 |
| Real      | quickdraw  | 75.8  | **77.0** | 87.9 |
| Real      | clipart    | 75.8  | 47.8     | 62.1 |
| Real      | infograph  | 75.8  | 31.1     | 42.5 |
| Real      | painting   | 74.9  | 39.0     | 55.6 |



**实验分析**

一、**向 Real 的迁移（下游为 Real）**

- 向 Real 迁移时，**clipart** 的 MR 最高（68.7），重编程效果最好。

- **quickdraw** FID 虽大，但其迁移效果好，说明 Real 能够从其学到鲁棒特征。

- MR 和 FFT 在这组中 **一致偏高**，表明从其他子域迁移到 Real 相对容易。

二，**向 domainnet 域的迁移**

- **在 Real → X 的迁移中，MR 与 FID 呈“非单调弱相关”**：高 FID 不一定带来低 MR。

  **quickdraw 是最容易通过模型重编程迁移的目标域**，尽管其分布差异最大，表明：

  - 模型重编程不依赖视觉近似
  - 更依赖图像语义结构是否“可映射”

  **infograph 是最难迁移的目标域**，说明它在语义空间中与 real 差异较大。



三，**整体分析**

##### **Real → X** 

###### 1. **整体趋势对比：MR vs FFT**

- 大多数迁移方向上，**FFT > MR**，说明微调在充分数据下表现更强；
- 但在 **某些高分布距离对**中，MR 表现接近甚至优于 FFT，这体现出 **重编程在低资源/大分布差异迁移中的潜力**。

###### 2. **逐方向分析差值（FFT - MR）**



| 迁移方向         | MR   | FFT  | FID (`real→ target`) | Δ = FFT - MR | 分析                                                         |
| ---------------- | ---- | ---- | -------------------- | ------------ | ------------------------------------------------------------ |
| Real → quickdraw | 77.0 | 87.9 | 336.36               | **+10.9**    | 分布距离最大，FFT 虽更强，但 MR 保持较高性能，显示其在极端分布偏移下的迁移鲁棒性。 |
| Real → sketch    | 41.2 | 50.6 | 203.97               | **+9.4**     | sketch 风格独特，分布差异中等，FFT 略优但 MR 差距较小，表现较稳。 |
| Real → clipart   | 47.8 | 62.1 | 197.53               | **+14.3**    | 分布差异中等，FFT 获得明显提升，MR 相对劣势较大，可能因结构特征差异难以适应。 |
| Real → infograph | 31.1 | 42.5 | 197.53               | **+11.4**    | 迁移难度最高任务之一，MR 效果受限，FFT 相对更能适应图文混合结构的目标域。 |
| Real → painting  | 39.0 | 55.6 | 160.04               | **+16.6**    | 虽为视觉风格最接近的目标域，FFT 显著优于 MR，表明在可微调条件下更易受益，而 MR 表现受限。 |

###### 3. **是否有 MR 更优的方向？**

在目前这张表中，**FFT 全部优于 MR**，但**优势幅度有限（最大也只有十几个点）**，说明：

> 虽然 fine-tuning 整体表现更强，但 MR 的表现也具有一定竞争力，尤其在 quickdraw 这种“分布极远 + 图像风格极端”的目标域中，MR 能保持 77.0 的性能，是非常不错的迁移基线。

**实验结论**：**在源域与目标域存在较大分布差异的迁移任务中，MR 方法的性能相对微调（FFT）更加接近，表现出更强的跨域鲁棒性。**

##### **X → Real** 

| Upstream  | FID (`source → real`) | MR   | FFT  | Δ = FFT - MR     |
| --------- | --------------------- | ---- | ---- | ---------------- |
| quickdraw | **336.36**            | 53.7 | 66.0 | **12.3**         |
| sketch    | 203.97                | 59.7 | 72.9 | **13.2**         |
| clipart   | 197.53                | 68.7 | 79.7 | **11.0**         |
| infograph | 197.53                | 56.5 | 72.9 | **16.4（最大）** |
| painting  | 160.04                | 61.9 | 71.0 | 10.1             |

- 在 FID 最大的 **quickdraw → real** 中，MR 与 FFT 的差距是 **12.3**；
- 在 FID 中等的 **clipart → real** 中，差距 **最小**（11.0）；
- 在 FID 接近但视觉结构差异大的 **infograph → real** 中，MR 和 FFT 差距最大（16.4）；
- 整体来看，“分布差异越大 → MR 趋近于 FFT”的结论在这个方向**仍然部分成立**，但**不如 real → other 的趋势明显和线性**。

**在其他子域迁移至 real 的任务中，MR 与 FFT 的性能差距仍与分布距离有关，但趋势不如 real → other 明显。**
 尤其在 infograph → real 迁移中，即使分布距离与 clipart 相近，MR 与 FFT 的差距却最大，说明此时 MR 表征能力可能受到限制。
 然而，在 quickdraw/sketch 等强偏移源域中，MR 的稳定性再次体现，使其在迁移距离极大时依然具有一定优势。





本实验评估了模型重编程（Model Reprogramming）在跨域场景中的表现，重点关注从**非真实图像域（如 Quickdraw、Sketch、Clipart、Infograph、Painting）**迁移至**真实图像域（Real）**的效果。

从表中结果来看：

- 当上游为 **Quickdraw、Clipart、Sketch、Infograph、Painting**，下游为 **Real** 时，模型在 MR 指标上取得了较为显著的性能，**平均 MR 达到 61.9**，显示出模型在该方向具备较强的迁移适应能力。

- 最佳表现来自 **Clipart → Real**，其 MR 值为 **68.7**，其次为 **Quickdraw → Real**（64.9）和 **Painting → Real**（61.9），说明从风格化或抽象化图像迁移到真实图像时，模型能够较好地提取通用语义特征。

- 尽管上游数据具有较大的风格差异，如手绘风（Sketch）、图标风（Infograph），模型依然能通过重编程学到有效的适配模式，体现出一定的鲁棒性。

与之对比，**从 Real 域迁移到非真实图像域**时的 MR 值整体偏低（如 Real → Infograph 为 31.1，Real → Clipart 为 47.8），说明该方向的迁移更具挑战性。

因此，实验结果表明：

​	模型重编程在“从非真实图像域迁移到真实图像域”方向表现出更强的跨域适应能力。这表明重编程机制有助于将抽象风格图像中的底层语义特征映射至更结构化的真实图像表示，从而提升分类性能。







#### 实验 3 ：噪声对model reporgramming 的影响 

**实验设计：**

这里我们在输入端对所有图片加噪声 ，选用的噪声包括 （**Gaussian , salt peper , blur**） 来测量噪声对于model reprogramming 的影响

**model reprogramming** 从本质上是一种对于输入的扰动 ，也是噪声 。 因此我的猜测是这两种噪声会让该方法更难去学到特征。

下面选取了 Vit-b16 和 resnet18 两种模型 ， CIFAR10， CIFAR100，SVHN 三种数据集



**Resnet18**

|          | MR(with Gaussion noise) | MR(with blur noise) | MR(with salt paper noise) | MR   |
| -------- | ----------------------- | ------------------- | ------------------------- | ---- |
| Cifar10  | 59.8                    | 65.6                | 64.0                      | 72.8 |
| Cifar100 | 15.6                    | 16.5                | 20.1                      | 39.4 |
| SVHN     | 87.3                    | 88.0                | 82.8                      | 84.4 |



**Vit** 

|          | MR(with Gaussion noise) | MR(with blur noise) | MR(with salt paper noise) | MR       |
| -------- | ----------------------- | ------------------- | ------------------------- | -------- |
| Cifar10  | 60.5                    | **66.3**            | **66.3**                  | 63.9     |
| Cifar100 | 20.4                    | 24.8                | 22.9                      | **27.0** |
| SVHN     | 66.6                    | **86.7**            | 85.3                      | 85.3     |



1. **对 ResNet18 来看：**
   - **在 CIFAR-10 和 SVHN 上，blur 和 salt-pepper 噪声的影响比 Gaussian 小**，说明模型对结构模糊较为鲁棒；
   - CIFAR-100 上 MR 对噪声极其敏感（下降超过 20 点），说明在复杂任务下重编程鲁棒性下降更明显；
   - FFT 方法整体表现强，噪声影响下准确率依然较高。
2. **对 ViT 来看：**
   - ViT 模型整体对噪声更加鲁棒，尤其在 SVHN 上噪声下的 MR 基本持平（66.6–86.7），远优于 ResNet18；
   - ViT 的结构对 blur、salt-pepper 噪声更不敏感，说明 Transformer 架构在重编程下**保留更多全局信息**；
   - CIFAR-100 的表现依旧较弱，说明模型结构并不能完全抵抗复杂分类任务下的噪声干扰。

**几乎所有任务中，噪声都会显著降低 MR 的性能**

- 在 **CIFAR-10 / ResNet18** 上，MR 从 72.8 降低至：
  - Gaussian：59.8（↓13.0）
  - Blur：65.6（↓7.2）
  - Salt-pepper：64.0（↓8.8）
- **CIFAR-100** 更极端，从 39.4 降到 15.6（↓23.8，Gaussian）

说明 MR **非常依赖输入图像的清晰度和结构信息完整性**，一旦图像出现扰动，前端视觉提示难以构造稳定映射。