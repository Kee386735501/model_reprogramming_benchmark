{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall torch -y\n",
    "# !pip cache purge\n",
    "# !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "\n",
    "# GTSRB dataset label\n",
    "GTSRB_LABEL_MAP = {\n",
    "    '0': '20_speed',\n",
    "    '1': '30_speed',\n",
    "    '2': '50_speed',\n",
    "    '3': '60_speed',\n",
    "    '4': '70_speed',\n",
    "    '5': '80_speed',\n",
    "    '6': '80_lifted',\n",
    "    '7': '100_speed',\n",
    "    '8': '120_speed',\n",
    "    '9': 'no_overtaking_general',\n",
    "    '10': 'no_overtaking_trucks',\n",
    "    '11': 'right_of_way_crossing',\n",
    "    '12': 'right_of_way_general',\n",
    "    '13': 'give_way',\n",
    "    '14': 'stop',\n",
    "    '15': 'no_way_general',\n",
    "    '16': 'no_way_trucks',\n",
    "    '17': 'no_way_one_way',\n",
    "    '18': 'attention_general',\n",
    "    '19': 'attention_left_turn',\n",
    "    '20': 'attention_right_turn',\n",
    "    '21': 'attention_curvy',\n",
    "    '22': 'attention_bumpers',\n",
    "    '23': 'attention_slippery',\n",
    "    '24': 'attention_bottleneck',\n",
    "    '25': 'attention_construction',\n",
    "    '26': 'attention_traffic_light',\n",
    "    '27': 'attention_pedestrian',\n",
    "    '28': 'attention_children',\n",
    "    '29': 'attention_bikes',\n",
    "    '30': 'attention_snowflake',\n",
    "    '31': 'attention_deer',\n",
    "    '32': 'lifted_general',\n",
    "    '33': 'turn_right',\n",
    "    '34': 'turn_left',\n",
    "    '35': 'turn_straight',\n",
    "    '36': 'turn_straight_right',\n",
    "    '37': 'turn_straight_left',\n",
    "    '38': 'turn_right_down',\n",
    "    '39': 'turn_left_down',\n",
    "    '40': 'turn_circle',\n",
    "    '41': 'lifted_no_overtaking_general',\n",
    "    '42': 'lifted_no_overtaking_trucks'\n",
    "}\n",
    "\n",
    "\n",
    "# imagenetclasses labels \n",
    "IMAGENETCLASSES = ['tench', 'goldfish', 'great white shark', 'tiger shark', 'hammerhead', 'electric ray', 'stingray', 'cock', 'hen', 'ostrich', 'brambling', 'goldfinch', 'house finch', 'junco', 'indigo bunting', 'robin', 'bulbul', 'jay', 'magpie', 'chickadee', 'water ouzel', 'kite', 'bald eagle', 'vulture', 'great grey owl', 'European fire salamander', 'common newt', 'eft', 'spotted salamander', 'axolotl', 'bullfrog', 'tree frog', 'tailed frog', 'loggerhead', 'leatherback turtle', 'mud turtle', 'terrapin', 'box turtle', 'banded gecko', 'common iguana', 'American chameleon', 'whiptail', 'agama', 'frilled lizard', 'alligator lizard', 'Gila monster', 'green lizard', 'African chameleon', 'Komodo dragon', 'African crocodile', 'American alligator', 'triceratops', 'thunder snake', 'ringneck snake', 'hognose snake', 'green snake', 'king snake', 'garter snake', 'water snake', 'vine snake', 'night snake', 'boa constrictor', 'rock python', 'Indian cobra', 'green mamba', 'sea snake', 'horned viper', 'diamondback', 'sidewinder', 'trilobite', 'harvestman', 'scorpion', 'black and gold garden spider', 'barn spider', 'garden spider', 'black widow', 'tarantula', 'wolf spider', 'tick', 'centipede', 'black grouse', 'ptarmigan', 'ruffed grouse', 'prairie chicken', 'peacock', 'quail', 'partridge', 'African grey', 'macaw', 'sulphur-crested cockatoo', 'lorikeet', 'coucal', 'bee eater', 'hornbill', 'hummingbird', 'jacamar', 'toucan', 'drake', 'red-breasted merganser', 'goose', 'black swan', 'tusker', 'echidna', 'platypus', 'wallaby', 'koala', 'wombat', 'jellyfish', 'sea anemone', 'brain coral', 'flatworm', 'nematode', 'conch', 'snail', 'slug', 'sea slug', 'chiton', 'chambered nautilus', 'Dungeness crab', 'rock crab', 'fiddler crab', 'king crab', 'American lobster', 'spiny lobster', 'crayfish', 'hermit crab', 'isopod', 'white stork', 'black stork', 'spoonbill', 'flamingo', 'little blue heron', 'American egret', 'bittern', 'crane', 'limpkin', 'European gallinule', 'American coot', 'bustard', 'ruddy turnstone', 'red-backed sandpiper', 'redshank', 'dowitcher', 'oystercatcher', 'pelican', 'king penguin', 'albatross', 'grey whale', 'killer whale', 'dugong', 'sea lion', 'Chihuahua', 'Japanese spaniel', 'Maltese dog', 'Pekinese', 'Shih-Tzu', 'Blenheim spaniel', 'papillon', 'toy terrier', 'Rhodesian ridgeback', 'Afghan hound', 'basset', 'beagle', 'bloodhound', 'bluetick', 'black-and-tan coonhound', 'Walker hound', 'English foxhound', 'redbone', 'borzoi', 'Irish wolfhound', 'Italian greyhound', 'whippet', 'Ibizan hound', 'Norwegian elkhound', 'otterhound', 'Saluki', 'Scottish deerhound', 'Weimaraner', 'Staffordshire bullterrier', 'American Staffordshire terrier', 'Bedlington terrier', 'Border terrier', 'Kerry blue terrier', 'Irish terrier', 'Norfolk terrier', 'Norwich terrier', 'Yorkshire terrier', 'wire-haired fox terrier', 'Lakeland terrier', 'Sealyham terrier', 'Airedale', 'cairn', 'Australian terrier', 'Dandie Dinmont', 'Boston bull', 'miniature schnauzer', 'giant schnauzer', 'standard schnauzer', 'Scotch terrier', 'Tibetan terrier', 'silky terrier', 'soft-coated wheaten terrier', 'West Highland white terrier', 'Lhasa', 'flat-coated retriever', 'curly-coated retriever', 'golden retriever', 'Labrador retriever', 'Chesapeake Bay retriever', 'German short-haired pointer', 'vizsla', 'English setter', 'Irish setter', 'Gordon setter', 'Brittany spaniel', 'clumber', 'English springer', 'Welsh springer spaniel', 'cocker spaniel', 'Sussex spaniel', 'Irish water spaniel', 'kuvasz', 'schipperke', 'groenendael', 'malinois', 'briard', 'kelpie', 'komondor', 'Old English sheepdog', 'Shetland sheepdog', 'collie', 'Border collie', 'Bouvier des Flandres', 'Rottweiler', 'German shepherd', 'Doberman', 'miniature pinscher', 'Greater Swiss Mountain dog', 'Bernese mountain dog', 'Appenzeller', 'EntleBucher', 'boxer', 'bull mastiff', 'Tibetan mastiff', 'French bulldog', 'Great Dane', 'Saint Bernard', 'Eskimo dog', 'malamute', 'Siberian husky', 'dalmatian', 'affenpinscher', 'basenji', 'pug', 'Leonberg', 'Newfoundland', 'Great Pyrenees', 'Samoyed', 'Pomeranian', 'chow', 'keeshond', 'Brabancon griffon', 'Pembroke', 'Cardigan', 'toy poodle', 'miniature poodle', 'standard poodle', 'Mexican hairless', 'timber wolf', 'white wolf', 'red wolf', 'coyote', 'dingo', 'dhole', 'African hunting dog', 'hyena', 'red fox', 'kit fox', 'Arctic fox', 'grey fox', 'tabby', 'tiger cat', 'Persian cat', 'Siamese cat', 'Egyptian cat', 'cougar', 'lynx', 'leopard', 'snow leopard', 'jaguar', 'lion', 'tiger', 'cheetah', 'brown bear', 'American black bear', 'ice bear', 'sloth bear', 'mongoose', 'meerkat', 'tiger beetle', 'ladybug', 'ground beetle', 'long-horned beetle', 'leaf beetle', 'dung beetle', 'rhinoceros beetle', 'weevil', 'fly', 'bee', 'ant', 'grasshopper', 'cricket', 'walking stick', 'cockroach', 'mantis', 'cicada', 'leafhopper', 'lacewing', 'dragonfly', 'damselfly', 'admiral', 'ringlet', 'monarch', 'cabbage butterfly', 'sulphur butterfly', 'lycaenid', 'starfish', 'sea urchin', 'sea cucumber', 'wood rabbit', 'hare', 'Angora', 'hamster', 'porcupine', 'fox squirrel', 'marmot', 'beaver', 'guinea pig', 'sorrel', 'zebra', 'hog', 'wild boar', 'warthog', 'hippopotamus', 'ox', 'water buffalo', 'bison', 'ram', 'bighorn', 'ibex', 'hartebeest', 'impala', 'gazelle', 'Arabian camel', 'llama', 'weasel', 'mink', 'polecat', 'black-footed ferret', 'otter', 'skunk', 'badger', 'armadillo', 'three-toed sloth', 'orangutan', 'gorilla', 'chimpanzee', 'gibbon', 'siamang', 'guenon', 'patas', 'baboon', 'macaque', 'langur', 'colobus', 'proboscis monkey', 'marmoset', 'capuchin', 'howler monkey', 'titi', 'spider monkey', 'squirrel monkey', 'Madagascar cat', 'indri', 'Indian elephant', 'African elephant', 'lesser panda', 'giant panda', 'barracouta', 'eel', 'coho', 'rock beauty', 'anemone fish', 'sturgeon', 'gar', 'lionfish', 'puffer', 'abacus', 'abaya', 'academic gown', 'accordion', 'acoustic guitar', 'aircraft carrier', 'airliner', 'airship', 'altar', 'ambulance', 'amphibian', 'analog clock', 'apiary', 'apron', 'ashcan', 'assault rifle', 'backpack', 'bakery', 'balance beam', 'balloon', 'ballpoint', 'Band Aid', 'banjo', 'bannister', 'barbell', 'barber chair', 'barbershop', 'barn', 'barometer', 'barrel', 'barrow', 'baseball', 'basketball', 'bassinet', 'bassoon', 'bathing cap', 'bath towel', 'bathtub', 'beach wagon', 'beacon', 'beaker', 'bearskin', 'beer bottle', 'beer glass', 'bell cote', 'bib', 'bicycle-built-for-two', 'bikini', 'binder', 'binoculars', 'birdhouse', 'boathouse', 'bobsled', 'bolo tie', 'bonnet', 'bookcase', 'bookshop', 'bottlecap', 'bow', 'bow tie', 'brass', 'brassiere', 'breakwater', 'breastplate', 'broom', 'bucket', 'buckle', 'bulletproof vest', 'bullet train', 'butcher shop', 'cab', 'caldron', 'candle', 'cannon', 'canoe', 'can opener', 'cardigan', 'car mirror', 'carousel', \"carpenter's kit\", 'carton', 'car wheel', 'cash machine', 'cassette', 'cassette player', 'castle', 'catamaran', 'CD player', 'cello', 'cellular telephone', 'chain', 'chainlink fence', 'chain mail', 'chain saw', 'chest', 'chiffonier', 'chime', 'china cabinet', 'Christmas stocking', 'church', 'cinema', 'cleaver', 'cliff dwelling', 'cloak', 'clog', 'cocktail shaker', 'coffee mug', 'coffeepot', 'coil', 'combination lock', 'computer keyboard', 'confectionery', 'container ship', 'convertible', 'corkscrew', 'cornet', 'cowboy boot', 'cowboy hat', 'cradle', 'crane', 'crash helmet', 'crate', 'crib', 'Crock Pot', 'croquet ball', 'crutch', 'cuirass', 'dam', 'desk', 'desktop computer', 'dial telephone', 'diaper', 'digital clock', 'digital watch', 'dining table', 'dishrag', 'dishwasher', 'disk brake', 'dock', 'dogsled', 'dome', 'doormat', 'drilling platform', 'drum', 'drumstick', 'dumbbell', 'Dutch oven', 'electric fan', 'electric guitar', 'electric locomotive', 'entertainment center', 'envelope', 'espresso maker', 'face powder', 'feather boa', 'file', 'fireboat', 'fire engine', 'fire screen', 'flagpole', 'flute', 'folding chair', 'football helmet', 'forklift', 'fountain', 'fountain pen', 'four-poster', 'freight car', 'French horn', 'frying pan', 'fur coat', 'garbage truck', 'gasmask', 'gas pump', 'goblet', 'go-kart', 'golf ball', 'golfcart', 'gondola', 'gong', 'gown', 'grand piano', 'greenhouse', 'grille', 'grocery store', 'guillotine', 'hair slide', 'hair spray', 'half track', 'hammer', 'hamper', 'hand blower', 'hand-held computer', 'handkerchief', 'hard disc', 'harmonica', 'harp', 'harvester', 'hatchet', 'holster', 'home theater', 'honeycomb', 'hook', 'hoopskirt', 'horizontal bar', 'horse cart', 'hourglass', 'iPod', 'iron', \"jack-o'-lantern\", 'jean', 'jeep', 'jersey', 'jigsaw puzzle', 'jinrikisha', 'joystick', 'kimono', 'knee pad', 'knot', 'lab coat', 'ladle', 'lampshade', 'laptop', 'lawn mower', 'lens cap', 'letter opener', 'library', 'lifeboat', 'lighter', 'limousine', 'liner', 'lipstick', 'Loafer', 'lotion', 'loudspeaker', 'loupe', 'lumbermill', 'magnetic compass', 'mailbag', 'mailbox', 'maillot', 'maillot', 'manhole cover', 'maraca', 'marimba', 'mask', 'matchstick', 'maypole', 'maze', 'measuring cup', 'medicine chest', 'megalith', 'microphone', 'microwave', 'military uniform', 'milk can', 'minibus', 'miniskirt', 'minivan', 'missile', 'mitten', 'mixing bowl', 'mobile home', 'Model T', 'modem', 'monastery', 'monitor', 'moped', 'mortar', 'mortarboard', 'mosque', 'mosquito net', 'motor scooter', 'mountain bike', 'mountain tent', 'mouse', 'mousetrap', 'moving van', 'muzzle', 'nail', 'neck brace', 'necklace', 'nipple', 'notebook', 'obelisk', 'oboe', 'ocarina', 'odometer', 'oil filter', 'organ', 'oscilloscope', 'overskirt', 'oxcart', 'oxygen mask', 'packet', 'paddle', 'paddlewheel', 'padlock', 'paintbrush', 'pajama', 'palace', 'panpipe', 'paper towel', 'parachute', 'parallel bars', 'park bench', 'parking meter', 'passenger car', 'patio', 'pay-phone', 'pedestal', 'pencil box', 'pencil sharpener', 'perfume', 'Petri dish', 'photocopier', 'pick', 'pickelhaube', 'picket fence', 'pickup', 'pier', 'piggy bank', 'pill bottle', 'pillow', 'ping-pong ball', 'pinwheel', 'pirate', 'pitcher', 'plane', 'planetarium', 'plastic bag', 'plate rack', 'plow', 'plunger', 'Polaroid camera', 'pole', 'police van', 'poncho', 'pool table', 'pop bottle', 'pot', \"potter's wheel\", 'power drill', 'prayer rug', 'printer', 'prison', 'projectile', 'projector', 'puck', 'punching bag', 'purse', 'quill', 'quilt', 'racer', 'racket', 'radiator', 'radio', 'radio telescope', 'rain barrel', 'recreational vehicle', 'reel', 'reflex camera', 'refrigerator', 'remote control', 'restaurant', 'revolver', 'rifle', 'rocking chair', 'rotisserie', 'rubber eraser', 'rugby ball', 'rule', 'running shoe', 'safe', 'safety pin', 'saltshaker', 'sandal', 'sarong', 'sax', 'scabbard', 'scale', 'school bus', 'schooner', 'scoreboard', 'screen', 'screw', 'screwdriver', 'seat belt', 'sewing machine', 'shield', 'shoe shop', 'shoji', 'shopping basket', 'shopping cart', 'shovel', 'shower cap', 'shower curtain', 'ski', 'ski mask', 'sleeping bag', 'slide rule', 'sliding door', 'slot', 'snorkel', 'snowmobile', 'snowplow', 'soap dispenser', 'soccer ball', 'sock', 'solar dish', 'sombrero', 'soup bowl', 'space bar', 'space heater', 'space shuttle', 'spatula', 'speedboat', 'spider web', 'spindle', 'sports car', 'spotlight', 'stage', 'steam locomotive', 'steel arch bridge', 'steel drum', 'stethoscope', 'stole', 'stone wall', 'stopwatch', 'stove', 'strainer', 'streetcar', 'stretcher', 'studio couch', 'stupa', 'submarine', 'suit', 'sundial', 'sunglass', 'sunglasses', 'sunscreen', 'suspension bridge', 'swab', 'sweatshirt', 'swimming trunks', 'swing', 'switch', 'syringe', 'table lamp', 'tank', 'tape player', 'teapot', 'teddy', 'television', 'tennis ball', 'thatch', 'theater curtain', 'thimble', 'thresher', 'throne', 'tile roof', 'toaster', 'tobacco shop', 'toilet seat', 'torch', 'totem pole', 'tow truck', 'toyshop', 'tractor', 'trailer truck', 'tray', 'trench coat', 'tricycle', 'trimaran', 'tripod', 'triumphal arch', 'trolleybus', 'trombone', 'tub', 'turnstile', 'typewriter keyboard', 'umbrella', 'unicycle', 'upright', 'vacuum', 'vase', 'vault', 'velvet', 'vending machine', 'vestment', 'viaduct', 'violin', 'volleyball', 'waffle iron', 'wall clock', 'wallet', 'wardrobe', 'warplane', 'washbasin', 'washer', 'water bottle', 'water jug', 'water tower', 'whiskey jug', 'whistle', 'wig', 'window screen', 'window shade', 'Windsor tie', 'wine bottle', 'wing', 'wok', 'wooden spoon', 'wool', 'worm fence', 'wreck', 'yawl', 'yurt', 'web site', 'comic book', 'crossword puzzle', 'street sign', 'traffic light', 'book jacket', 'menu', 'plate', 'guacamole', 'consomme', 'hot pot', 'trifle', 'ice cream', 'ice lolly', 'French loaf', 'bagel', 'pretzel', 'cheeseburger', 'hotdog', 'mashed potato', 'head cabbage', 'broccoli', 'cauliflower', 'zucchini', 'spaghetti squash', 'acorn squash', 'butternut squash', 'cucumber', 'artichoke', 'bell pepper', 'cardoon', 'mushroom', 'Granny Smith', 'strawberry', 'orange', 'lemon', 'fig', 'pineapple', 'banana', 'jackfruit', 'custard apple', 'pomegranate', 'hay', 'carbonara', 'chocolate sauce', 'dough', 'meat loaf', 'pizza', 'potpie', 'burrito', 'red wine', 'espresso', 'cup', 'eggnog', 'alp', 'bubble', 'cliff', 'coral reef', 'geyser', 'lakeside', 'promontory', 'sandbar', 'seashore', 'valley', 'volcano', 'ballplayer', 'groom', 'scuba diver', 'rapeseed', 'daisy', \"yellow lady's slipper\", 'corn', 'acorn', 'hip', 'buckeye', 'coral fungus', 'agaric', 'gyromitra', 'stinkhorn', 'earthstar', 'hen-of-the-woods', 'bolete', 'ear', 'toilet tissue']\n",
    "\n",
    "\n",
    "# cifar-10 labels \n",
    "CIFAR10CLASSES = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "\n",
    "# cifar-100 labels \n",
    "CIFAR100CLASSES = ['beaver', 'dolphin', 'otter', 'seal', 'whale', 'aquarium fish', 'flatfish', 'ray', 'shark', 'trout',\n",
    "                   'orchids', 'poppies', 'roses', 'sunflowers', 'tulips', 'bottles', 'bowls', 'cans', 'cups', 'plates',\n",
    "                   'apples', 'mushrooms', 'oranges', 'pears', 'sweet peppers', 'clock', 'computer keyboard', 'lamp', 'telephone', 'television',\n",
    "                   'bed', 'chair', 'couch', 'table', 'wardrobe', 'bee', 'beetle', 'butterfly', 'caterpillar', 'cockroach',\n",
    "                   'bear', 'leopard', 'lion', 'tiger', 'wolf', 'bridge', 'castle', 'house', 'road', 'skyscraper',\n",
    "                   'cloud', 'forest', 'mountain', 'plain', 'sea', 'camel', 'cattle', 'chimpanzee', 'elephant', 'kangaroo',\n",
    "                   'fox', 'porcupine', 'possum', 'raccoon', 'skunk', 'crab', 'lobster', 'snail', 'spider', 'worm', 'baby',\n",
    "                   'boy', 'girl', 'man', 'woman', 'crocodile', 'dinosaur', 'lizard', 'snake', 'turtle', 'hamster', 'mouse',\n",
    "                   'rabbit', 'shrew', 'squirrel', 'maple', 'oak', 'palm', 'pine', 'willow', 'bicycle', 'bus', 'motorcycle',\n",
    "                   'pickup truck', 'train', 'lawn-mower', 'rocket', 'streetcar', 'tank', 'tractor']\n",
    "\n",
    "\n",
    "# ImageNet parameters \n",
    "IMAGENETNORMALIZE = {\n",
    "    'mean': [0.485, 0.456, 0.406],\n",
    "    'std': [0.229, 0.224, 0.225],\n",
    "}\n",
    "\n",
    "import os\n",
    "from torch.utils.data import DataLoader,Subset\n",
    "from torchvision import datasets\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 清理类别名称\n",
    "def refine_classnames(class_names):\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        class_names[i] = class_name.lower().replace('_', ' ').replace('-', ' ')\n",
    "    return class_names\n",
    "\n",
    "# 数据集采样 \n",
    "def get_subset(dataset,fraction):\n",
    "    if fraction < 1.0:\n",
    "        indices = np.random.choice(len(dataset),int(len(dataset) * fraction),replace = False)\n",
    "        dataset = Subset(dataset,indices)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "\n",
    "# 处理数据集\n",
    "def prepare_additive_data(dataset, data_path, preprocess, test_process=None, batch_size=256, shuffle=True,data_fraction=0.8):\n",
    "    data_path = os.path.join(data_path, dataset)\n",
    "    if not test_process:\n",
    "        test_process = preprocess\n",
    "    if dataset == \"cifar10\":\n",
    "        train_data = datasets.CIFAR10(root = data_path, train = True, download = True, transform = preprocess)\n",
    "        train_data = get_subset(train_data,data_fraction)\n",
    "        test_data = datasets.CIFAR10(root = data_path, train = False, download = True, transform = test_process)\n",
    "        class_names = refine_classnames(test_data.classes)\n",
    "        loaders = {\n",
    "            'train': DataLoader(train_data, batch_size, shuffle = shuffle, num_workers=0),\n",
    "            'test': DataLoader(test_data, batch_size, shuffle = False, num_workers=0),\n",
    "        }\n",
    "    elif dataset == \"cifar100\":\n",
    "        train_data = datasets.CIFAR100(root = data_path, train = True, download = True, transform = preprocess)\n",
    "        train_data = get_subset(train_data,data_fraction)\n",
    "        test_data = datasets.CIFAR100(root = data_path, train = False, download = True, transform = test_process)\n",
    "        class_names = refine_classnames(test_data.classes)\n",
    "        loaders = {\n",
    "            'train': DataLoader(train_data, batch_size, shuffle = shuffle, num_workers=0),\n",
    "            'test': DataLoader(test_data, batch_size, shuffle = False, num_workers=0),\n",
    "        }\n",
    "    elif dataset == \"svhn\":\n",
    "        train_data = datasets.SVHN(root = data_path, split=\"train\", download = True, transform = preprocess)\n",
    "        train_data = get_subset(train_data,data_fraction)\n",
    "        test_data = datasets.SVHN(root = data_path, split=\"test\", download = True, transform = test_process)\n",
    "        class_names = [f'{i}' for i in range(10)]\n",
    "        loaders = {\n",
    "            'train': DataLoader(train_data, batch_size, shuffle = shuffle, num_workers=0),\n",
    "            'test': DataLoader(test_data, batch_size, shuffle = False, num_workers=0),\n",
    "        }\n",
    "    elif dataset == \"gtsrb\":\n",
    "        train_data = datasets.GTSRB(root = data_path, split=\"train\", download = True, transform = preprocess)\n",
    "        train_data = get_subset(train_data,data_fraction)\n",
    "        test_data = datasets.GTSRB(root = data_path, split=\"test\", download = True, transform = test_process)\n",
    "        class_names = refine_classnames(list(GTSRB_LABEL_MAP.values()))\n",
    "        loaders = {\n",
    "            'train': DataLoader(train_data, batch_size, shuffle = shuffle, num_workers=0),\n",
    "            'test': DataLoader(test_data, batch_size, shuffle = False, num_workers=0),\n",
    "        }\n",
    "    else:\n",
    "        raise NotImplementedError(f\"{dataset} not supported\")\n",
    "\n",
    "    return loaders, class_names\n",
    "\n",
    "\n",
    "# structure of the mask_cnn , mask generator \n",
    "!pip install scipy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class AttributeNet(nn.Module):\n",
    "    def __init__(self, layers=5, patch_size=8, channels=3):\n",
    "        super(AttributeNet, self).__init__()\n",
    "        self.layers = layers\n",
    "        self.patch_size = patch_size\n",
    "        self.channels = channels\n",
    "\n",
    "        self.pooling = nn.MaxPool2d(2, 2)\n",
    "        self.conv1 = nn.Conv2d(3, 8, 3, 1, 1) # in_channels , out_channels , kernel_size,stride,padding\n",
    "        self.bn1 = nn.BatchNorm2d(8)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(8, 16, 3, 1, 1)\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.conv3 = nn.Conv2d(16, 32, 3, 1, 1)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "        self.relu3 = nn.ReLU(inplace=True)\n",
    "        self.conv4 = nn.Conv2d(32, 64, 3, 1, 1)\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "        self.relu4 = nn.ReLU(inplace=True)\n",
    "        if self.layers == 5 and self.channels == 3:\n",
    "            self.conv6 = nn.Conv2d(64, 3, 3, 1, 1)\n",
    "        elif self.layers == 6:\n",
    "            self.conv5 = nn.Conv2d(64, 128, 3, 1, 1)\n",
    "            self.bn5 = nn.BatchNorm2d(128)\n",
    "            self.relu5 = nn.ReLU(inplace=True)\n",
    "\n",
    "            if self.channels == 3:\n",
    "                self.conv6 = nn.Conv2d(128, 3, 3, 1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.conv1(x)\n",
    "        y = self.bn1(y)\n",
    "        y = self.relu1(y)\n",
    "        if self.patch_size in [2, 4, 8, 16, 32]:\n",
    "            y = self.pooling(y)\n",
    "        y = self.conv2(y)\n",
    "        y = self.bn2(y)\n",
    "        y = self.relu2(y)\n",
    "        if self.patch_size in [4, 8, 16, 32]:\n",
    "            y = self.pooling(y)\n",
    "        y = self.conv3(y)\n",
    "        y = self.bn3(y)\n",
    "        y = self.relu3(y)\n",
    "        if self.patch_size in [8, 16, 32]:\n",
    "            y = self.pooling(y)\n",
    "        y = self.conv4(y)\n",
    "        y = self.bn4(y)\n",
    "        y = self.relu4(y)\n",
    "        if self.patch_size in [16, 32]:\n",
    "            y = self.pooling(y)\n",
    "        if self.layers == 6:\n",
    "            y = self.conv5(y)\n",
    "            y = self.bn5(y)\n",
    "            y = self.relu5(y)\n",
    "            if self.patch_size == 32:\n",
    "                y = self.pooling(y)\n",
    "\n",
    "        if self.channels == 3:\n",
    "            y = self.conv6(y)\n",
    "        elif self.channels == 1:\n",
    "            y = torch.mean(y, dim=1)\n",
    "        return y\n",
    "\n",
    "\n",
    "# the function is used to control the mask cnn \n",
    "class InstancewiseVisualPrompt(nn.Module):\n",
    "    def __init__(self, size, layers=5, patch_size=8, channels=3):\n",
    "        '''\n",
    "\n",
    "        Args:\n",
    "            size: input image size\n",
    "            layers: the number of layers of mask-training CNN\n",
    "            patch_size: the size of patches with the same mask value\n",
    "            channels: 3 means that the mask value for RGB channels are different, 1 means the same\n",
    "            keep_watermark: whether to keep the reprogram (\\delta) in the model\n",
    "        '''\n",
    "        super(InstancewiseVisualPrompt, self).__init__()\n",
    "        if layers not in [5, 6]:\n",
    "            raise ValueError(\"Input layer number is not supported\")\n",
    "        if patch_size not in [1, 2, 4, 8, 16, 32]:\n",
    "            raise ValueError(\"Input patch size is not supported\")\n",
    "        if channels not in [1, 3]:\n",
    "            raise ValueError(\"Input channel number is not supported\")\n",
    "        if patch_size == 32 and layers != 6:\n",
    "            raise ValueError(\"Input layer number and patch size are conflict with each other\")\n",
    "\n",
    "        # Set the attribute mask CNN\n",
    "        self.patch_num = int(size / patch_size)\n",
    "        self.imagesize = size\n",
    "        self.patch_size = patch_size\n",
    "        self.channels = channels\n",
    "        self.priority = AttributeNet(layers, patch_size, channels)\n",
    "\n",
    "        # Set reprogram (\\delta) according to the image size\n",
    "        self.size = size\n",
    "        self.program = torch.nn.Parameter(data=torch.zeros(3, size, size))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # patch-wise interpolation \n",
    "        attention = self.priority(x).view(-1, self.channels, self.patch_num * self.patch_num, 1).expand(-1, 3, -1, self.patch_size * self.patch_size).view(-1, 3, self.patch_num, self.patch_num, self.patch_size, self.patch_size).transpose(3, 4)\n",
    "        attention = attention.reshape(-1, 3, self.imagesize, self.imagesize)\n",
    "        x = x + self.program * attention\n",
    "        return x\n",
    "\n",
    "\n",
    "!pip install tqdm\n",
    "!pip install tensorboard\n",
    "!pip install matplotlib\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from functools import partial\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torchvision import transforms\n",
    "from tqdm.auto import tqdm  # ✅ 兼容 Notebook 和 Python 脚本，避免 multiprocessing 触发 PicklingError\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import csv\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "data_path = '.\\data'\n",
    "\n",
    "\n",
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "def get_config(pretrained):\n",
    "    '''\n",
    "    this is a function to control parameter for different pretrained model \n",
    "    Args:\n",
    "        dataset: string of the dataset name\n",
    "        pretrained: string of the pretrained model's name\n",
    "\n",
    "    Returns:\n",
    "        attribute_layers: the layer number of the attribute network\n",
    "        epochs: number of training epochs\n",
    "        lr: learning rate of reprogramming\n",
    "        attr_lr: learning rate of attribute network\n",
    "        attr_gamma: weight decay of attribute network\n",
    "    '''\n",
    "    epochs = 50\n",
    "    lr = 0.02\n",
    "\n",
    "    if pretrained == 'ViT_B32':\n",
    "        attribute_layers = 6\n",
    "        attr_lr = 0.001\n",
    "        attr_gamma = 1\n",
    "    else:\n",
    "        attribute_layers = 5\n",
    "        attr_lr = 0.01\n",
    "        attr_gamma = 0.1\n",
    "\n",
    "    return attribute_layers, epochs, lr, attr_lr, attr_gamma\n",
    "\n",
    "from torch.nn.functional import one_hot\n",
    "\n",
    "\n",
    "def get_dist_matrix(fx, y):\n",
    "    fx = one_hot(torch.argmax(fx, dim = -1), num_classes=fx.size(-1))\n",
    "    dist_matrix = [fx[y==i].sum(0).unsqueeze(1) for i in range(len(y.unique()))]\n",
    "    dist_matrix = torch.cat(dist_matrix, dim=1)\n",
    "    return dist_matrix\n",
    "\n",
    "def predictive_distribution_based_multi_label_mapping(dist_matrix, mlm_num: int):\n",
    "    assert mlm_num * dist_matrix.size(1) <= dist_matrix.size(0), \"source label number not enough for mapping\"\n",
    "    mapping_matrix = torch.zeros_like(dist_matrix, dtype=int)\n",
    "    dist_matrix_flat = dist_matrix.flatten()\n",
    "    for _ in range(mlm_num * dist_matrix.size(1)):\n",
    "        loc = dist_matrix_flat.argmax().item()\n",
    "        loc = [loc // dist_matrix.size(1), loc % dist_matrix.size(1)]\n",
    "        mapping_matrix[loc[0], loc[1]] = 1\n",
    "        dist_matrix[loc[0]] = -1\n",
    "        if mapping_matrix[:, loc[1]].sum() == mlm_num:\n",
    "            dist_matrix[:, loc[1]] = -1\n",
    "    return mapping_matrix\n",
    "\n",
    "\n",
    "def generate_label_mapping_by_frequency(visual_prompt, network, data_loader, mapping_num = 1): # mapping_num=1: 1V1 match\n",
    "    device = next(visual_prompt.parameters()).device\n",
    "    print(device)\n",
    "    if hasattr(network, \"eval\"):\n",
    "        network.eval()\n",
    "    fx0s = []\n",
    "    ys = []\n",
    "    dataset = data_loader.dataset  # 获取原始数据集\n",
    "    print(f\"Dataset length: {len(dataset)}\")\n",
    "    pbar = tqdm(data_loader, total=len(data_loader), desc=f\"Frequency Label Mapping\", ncols=100) if len(data_loader) > 20 else data_loader\n",
    "    # print(f\"DataLoader has {len(data_loader)} batches\")\n",
    "    for x, y in pbar:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        with torch.no_grad():\n",
    "            # \n",
    "            fx0 = network(visual_prompt(x))\n",
    "        fx0s.append(fx0)\n",
    "        ys.append(y)\n",
    "    fx0s = torch.cat(fx0s).cpu().float()\n",
    "    ys = torch.cat(ys).cpu().int()\n",
    "    if ys.size(0) != fx0s.size(0):\n",
    "        assert fx0s.size(0) % ys.size(0) == 0\n",
    "        ys = ys.repeat(int(fx0s.size(0) / ys.size(0)))\n",
    "    dist_matrix = get_dist_matrix(fx0s, ys)\n",
    "    pairs = torch.nonzero(predictive_distribution_based_multi_label_mapping(dist_matrix, mapping_num)) # (C, C) 原来i类对应现在的j类, j=0,1,...,C\n",
    "    mapping_sequence = pairs[:, 0][torch.sort(pairs[:, 1]).indices.tolist()]\n",
    "    return mapping_sequence\n",
    "\n",
    "\n",
    "def label_mapping_base(logits, mapping_sequence):\n",
    "    modified_logits = logits[:, mapping_sequence]\n",
    "    return modified_logits\n",
    "\n",
    "\n",
    "#  parameters \n",
    "\n",
    "IMAGENETNORMALIZE = {\n",
    "    'mean': [0.485, 0.456, 0.406],\n",
    "    'std': [0.229, 0.224, 0.225],\n",
    "}\n",
    "\n",
    "\n",
    "class Args:\n",
    "\n",
    "    \"\"\"\n",
    "    this is parameter setting for smm training process\n",
    "    \"\"\"\n",
    "    network = \"resnet18\"  # 可选: \"resnet18\", \"resnet50\", \"ViT_B32\"\n",
    "    seed = 0\n",
    "    dataset = \"cifar100\"  # 可选: \"cifar10\", \"cifar100\", \"gtsrb\", \"svhn\"\n",
    "    patch_size = 8\n",
    "    attribute_channels = 3\n",
    "    mapping_method = \"ilm\"\n",
    "    attribute_layers = 5 # 5 or 6\n",
    "    fraction = 0.8\n",
    "\n",
    "args = Args()\n",
    "if args.network == \"ViT_B32\":\n",
    "    imgsize = 384\n",
    "else:\n",
    "    imgsize = 224\n",
    "\n",
    "# data enhenced\n",
    "\n",
    "def to_rgb(image):\n",
    "    \"\"\"确保图像是 RGB 格式\"\"\"\n",
    "    return image.convert('RGB') if hasattr(image, 'convert') else image\n",
    "\n",
    "\n",
    "train_preprocess = transforms.Compose([\n",
    "    transforms.Resize((imgsize + 32, imgsize + 32)),\n",
    "    transforms.RandomCrop(imgsize),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.Lambda(to_rgb),  \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(IMAGENETNORMALIZE['mean'], IMAGENETNORMALIZE['std']),\n",
    "])\n",
    "\n",
    "test_preprocess = transforms.Compose([\n",
    "    transforms.Resize((imgsize, imgsize)),\n",
    "    transforms.Lambda(to_rgb),  \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(IMAGENETNORMALIZE['mean'], IMAGENETNORMALIZE['std']),\n",
    "])\n",
    "loaders, class_names = prepare_additive_data(args.dataset, data_path=data_path, preprocess=train_preprocess,\n",
    "                                                    test_process=test_preprocess,data_fraction=args.fraction)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 设备检测\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "!pip install pytorch_pretrained_vit\n",
    "\n",
    "#Edit the Path\n",
    "data_path = os.path.join(\".\", \"dataset\")  # 当前目录的 dataset 子目录\n",
    "results_path = os.path.join(\".\", \"dataset\")  # 兼容 Windows 和 Linux/macOS\n",
    "\n",
    "!pip install pytorch_pretrained_vit\n",
    "# 设定路径\n",
    "save_path = os.path.join(results_path, f\"{args.dataset}_{args.network}_{args.mapping_method}_s{args.seed}_ch{args.attribute_channels}_l{args.attribute_layers}_p{args.patch_size}\")\n",
    "\n",
    "# Network \n",
    "if args.network == \"resnet18\":\n",
    "    from torchvision.models import resnet18, ResNet18_Weights\n",
    "    network = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1).to(device)\n",
    "elif args.network == \"resnet50\":\n",
    "    from torchvision.models import resnet50, ResNet50_Weights\n",
    "    network = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2).to(device)\n",
    "elif args.network == \"ViT_B32\":\n",
    "    from pytorch_pretrained_vit import ViT\n",
    "    model_name = 'B_32_imagenet1k'\n",
    "    network = ViT(model_name, pretrained=True).to(device)\n",
    "else:\n",
    "    raise NotImplementedError(f\"{args.network} is not supported\")\n",
    "\n",
    "network.requires_grad_(False)\n",
    "network.eval()\n",
    "\n",
    "# Visual Prompt\n",
    "visual_prompt = InstancewiseVisualPrompt(imgsize, args.attribute_layers, args.patch_size, args.attribute_channels).to(device)\n",
    "\n",
    "\n",
    "# optimizers\n",
    "attribute_layers, epochs, lr, attr_lr, attr_gamma = get_config(args.network)\n",
    "optimizer = torch.optim.Adam([{'params': visual_prompt.program, 'lr': lr}])\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,\n",
    "                                                        milestones=[int(0.5 * epochs), int(0.72 * epochs)],\n",
    "                                                        gamma=0.1)\n",
    "optimizer_att = torch.optim.Adam([{'params': visual_prompt.priority.parameters(), 'lr': attr_lr}])\n",
    "scheduler_att = torch.optim.lr_scheduler.MultiStepLR(optimizer_att,\n",
    "                                                    milestones=[int(0.5 * epochs), int(0.72 * epochs)],\n",
    "                                                    gamma=attr_gamma)\n",
    "\n",
    "# Make dir\n",
    "import os\n",
    "\n",
    "\n",
    "# label_mapping method\n",
    "if args.mapping_method == 'rlm':\n",
    "    mapping_sequence = torch.randperm(1000)[:len(class_names)]\n",
    "    label_mapping = partial(label_mapping_base, mapping_sequence=mapping_sequence)\n",
    "elif args.mapping_method == 'flm':\n",
    "    mapping_sequence = generate_label_mapping_by_frequency(visual_prompt, network, loaders['train'])\n",
    "    label_mapping = partial(label_mapping_base, mapping_sequence=mapping_sequence)\n",
    "\n",
    "\n",
    "\n",
    "# Train\n",
    "train_accs = []\n",
    "train_losses = []\n",
    "test_accs = []\n",
    "\n",
    "\n",
    "best_acc = 0.\n",
    "tr_acc = 0\n",
    "scaler = GradScaler()\n",
    "print(\"start training\")\n",
    "\n",
    "\n",
    "log_dir_smm = f\"./logs/smm\"\n",
    "writer = SummaryWriter(log_dir=log_dir_smm)\n",
    "\n",
    "import time\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    if args.mapping_method == 'ilm':\n",
    "        mapping_sequence = generate_label_mapping_by_frequency(visual_prompt, network, loaders['train'])\n",
    "        label_mapping = partial(label_mapping_base, mapping_sequence=mapping_sequence)\n",
    "    visual_prompt.train()\n",
    "    total_num = 0\n",
    "    true_num = 0\n",
    "    loss_sum = 0\n",
    "    print(f\"Epoch {epoch+1}/{epochs} training\")\n",
    "    pbar = tqdm(loaders['train'], total=len(loaders['train']),\n",
    "                desc=f\"Epo {epoch}\", ncols=100)\n",
    "    for x, y in pbar:\n",
    "        if x.get_device() == -1:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "        pbar.set_description_str(f\"Epo {epoch}\", refresh=True)\n",
    "        optimizer.zero_grad()\n",
    "        optimizer_att.zero_grad()\n",
    "        with autocast():\n",
    "            fx = label_mapping(network(visual_prompt(x)))\n",
    "            loss = F.cross_entropy(fx, y, reduction='mean')\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.step(optimizer_att)\n",
    "        scaler.update()\n",
    "        total_num += y.size(0)\n",
    "        true_num += torch.argmax(fx, 1).eq(y).float().sum().item()\n",
    "        loss_sum += loss.item() * fx.size(0)\n",
    "        pbar.set_postfix_str(f\"Acc {100 * true_num / total_num:.2f}%\")\n",
    "    epoch_time = time.time() - start_time\n",
    "    scheduler.step()\n",
    "    scheduler_att.step()\n",
    "    \n",
    "    train_accs.append(true_num / total_num)\n",
    "    tr_acc = true_num / total_num\n",
    "    train_losses.append(loss_sum / total_num)\n",
    "    print(\"train/acc\", true_num / total_num, epoch)\n",
    "    print(\"train/loss\", loss_sum / total_num, epoch)\n",
    "    writer.add_scalar(\"train/acc\", true_num / total_num, epoch)\n",
    "    writer.add_scalar(\"train/loss\", loss_sum / total_num, epoch)\n",
    "    writer.add_scalar(\"train/time\", epoch_time, epoch)\n",
    "\n",
    "\n",
    "    # Test\n",
    "    visual_prompt.eval()\n",
    "    total_num = 0\n",
    "    true_num = 0\n",
    "    loss_sum = 0\n",
    "    pbar = tqdm(loaders['test'], total=len(loaders['test']), desc=f\"Epo {epoch} Testing\", ncols=100)\n",
    "    ys = []\n",
    "    for x, y in pbar:\n",
    "        if x.get_device() == -1:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "        ys.append(y)\n",
    "        with torch.no_grad():\n",
    "            fx0 = network(visual_prompt(x))\n",
    "            fx = label_mapping(fx0)\n",
    "            loss = F.cross_entropy(fx, y, reduction='mean')\n",
    "        loss_sum += loss.item() * fx.size(0)\n",
    "        total_num += y.size(0)\n",
    "        true_num += torch.argmax(fx, 1).eq(y).float().sum().item()\n",
    "        acc = true_num / total_num\n",
    "        pbar.set_postfix_str(f\"Acc {100 * acc:.2f}%\")\n",
    "    print(\"test/acc\", acc, epoch)\n",
    "    print(\"test/loss\", loss_sum / total_num, epoch)\n",
    "    writer.add_scalar(\"test/acc\", acc, epoch)\n",
    "    writer.add_scalar(\"test/loss\", loss_sum / total_num, epoch)\n",
    "\n",
    "\n",
    "\n",
    "    # save data \n",
    "    train_acc = tr_acc\n",
    "    train_loss = loss_sum / total_num\n",
    "    train_accs.append(train_acc)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    # ====== 写入日志文件 ======\n",
    "    writer.flush()\n",
    "\n",
    "    # Save CKPT\n",
    "    state_dict = {\n",
    "        \"visual_prompt_dict\": visual_prompt.state_dict(),\n",
    "        \"epoch\": epoch,\n",
    "        \"best_acc\": best_acc,\n",
    "        \"mapping_sequence\": mapping_sequence,\n",
    "    }\n",
    "    if acc > best_acc:\n",
    "    #     best_acc = acc\n",
    "    #     state_dict['best_acc'] = best_acc\n",
    "    #     torch.save(state_dict, os.path.join(save_path, 'best.pth'))\n",
    "    # torch.save(state_dict, os.path.join(save_path, 'ckpt.pth'))\n",
    "        print(f\"Epoch {epoch} best accuracy: {best_acc:.2f}%\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
